---
title: "#40: Pinterest&#x27;s ML for board organization, GAN-aided pixel art, and Bayesian optimization gets the Distill treatment "
date: 2020-05-24
number: 40
aliases:
  - https://dynamicallytyped.com/issues/40-pinterest-s-ml-for-board-organization-gan-aided-pixel-art-and-bayesian-optimization-gets-the-distill-treatment-247582
---

Hey everyone, welcome to Dynamically Typed #40!
Today in productized AI I‚Äôm covering Pinterest‚Äôs new ML-based organization feature, and I have links to a meeting notes transcription tool and 3D photos on Facebook and the iPhone SE.
On the ML research side, I wrote about Distill‚Äôs new Bayesian optimization paper, and I have links to several new model visualization and training tools.
For climate AI there‚Äôs Google‚Äôs commitment to stop making AI tools for oil and gas extraction, as well as an update on Open Climate Fix.
Finally, for cool things I found pixel-me, a site that generates 8-bit style portraits based on photos, and a cool demo of self-learning digital squids.
Let‚Äôs dive in!

## Productized Artificial Intelligence üîå

![Pinterest's UX flow for ML-based grouping within boards. (Pinterest Engineering Blog.)](https://s3.amazonaws.com/revue/items/images/006/010/868/mail/41cba04a0d8e80572670ebc7f93785aa.png?1590240695)

_Pinterest's UX flow for ML-based grouping within boards. (Pinterest Engineering Blog.)_

**Pinterest has added new AI-powered functionality for grouping images and other pins on a board.**
The social media platform is mostly centered around finding images and collecting (pinning) them on boards.
After working on a board for a while, though, some users may pin so much that they no longer see the forest for the trees.
That‚Äôs where this new feature comes in:

> For example, maybe a Pinner is new to cooking but has been saving hundreds of recipe Pins.
> With this new tool, Pinterest may suggest board sections like ‚Äúveggie meals‚Äù and ‚Äúappetizers‚Äù to help the Pinner organize their board into a more actionable meal plan.

Here‚Äôs how it works:

1. When a user views a board that has a potential grouping, a suggestion pops up showing the suggested group and a few sample pins.
2. If the user taps it, the suggestion expands into a view with all the suggested pins, where she can deselect any pins she does not want to add to the group. (Which I‚Äôm sure is very valuable training data!)
3. The user can edit the name for the section, and then it gets added to her board.

Coming up with potential groupings is a three-step process.
First, [a graph convolutional network called PinSage](https://medium.com/pinterest-engineering/pinsage-a-new-graph-convolutional-neural-network-for-web-scale-recommender-systems-88795a107f48?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) computes an embedding based on text associated with the pin, visual features extracted from the image, and the graph structure.
Then the Ward clustering algorithm (chosen because it does not require a predefined number of clusters) generates potential groups.
Finally, a filtered count of common annotations for pins in the group decides the proposed group name.

Pinterest has really been on a roll lately with adding AI-powered features to its apps, including visual search ([DT #23](https://dynamicallytyped.com/issues/23-robotic-raspberry-and-lettuce-pickers-2-5-billion-objects-in-pinterest-lens-and-an-analysis-of-the-ai-reproducibility-crisis-199555?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) and AR try-on for shopping ([DT #33](https://dynamicallytyped.com/issues/33-billie-eilish-answers-ai-generated-interview-questions-visual-search-for-aerial-imagery-and-the-tech-won-t-drill-it-pledge-224742?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)).
[This post by Dana Yakoobinsky and Dafang He](https://medium.com/pinterest-engineering/using-machine-learning-to-auto-organize-boards-13a12b22bf5?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) on the company‚Äôs engineering blog has the full details on their implementation of this latest feature, as well as some future plans to expand it.

**Quick productized AI links üîå**

* ü¶¶ [Otter.ai](https://otter.ai/login?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) auto-generates ‚Äúrich notes for meetings, interviews, lectures, and other important conversations.‚Äù This looks like a fun product, and apparently it‚Äôs being integrated into Zoom. (Unrelated: the otter emoji [may be the purest emoji in existence](https://emojipedia.org/otter/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).)
* üì± Ben Sandofsky of iOS camera app Halide [wrote a deep dive](https://blog.halide.cam/iphone-se-the-one-eyed-king-96713d65a3b1?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) on how the new iPhone SE, which has only one rear-facing camera, uses single-image monocular depth estimation to do fake background blur in portrait mode photos. I have some experience with this exact computer vision task, and the results achieved here by Apple‚Äîon-device!‚Äîlook very impressive to me.
* üì∏ Related: [Facebook‚Äôs 3D photos feature now simulates depth for any image](https://venturebeat.com/2020/02/28/facebooks-3d-photos-feature-now-gives-any-image-simulated-depth/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), using techniques very similar to what the iPhone SE is doing.

## Machine Learning Research üéõ

![Bayesian optimization of finding gold along a line, using the probability of improvement (PI) acquisition function. (Agnihotri and Batra, 2020.)](https://s3.amazonaws.com/revue/items/images/006/010/478/mail/7957b79fcd3b61d95a8fb937d7eb551f.png?1590231014)

_Bayesian optimization of finding gold along a line, using the probability of improvement (PI) acquisition function. (Agnihotri and Batra, 2020.)_

Apoorv Agnihotri and Nipun Batra wrote an article [**Exploring Bayesian Optimization**](https://distill.pub/2020/bayesian-optimization/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) **for Distill.**
This technique is used in hyperparameter optimization, where evaluating any one point‚Äîlike the combination of a learning rate, a weight decay factor, and a data augmentation setting‚Äîis expensive: you need to train your entire model to know how well the hyperparameters performed.

This is where Bayesian optimization comes in.
It centers around answering the question ‚ÄúBased on what we know so far, what point should we evaluate next?‚Äù The process uses _acquisition functions_ to trade off exploitation (looking at points in the hyperparameter space that we think are likely to be good) with exploration (looking at points we‚Äôre very uncertain about).
Given an appropriate acquisition function and priors, it can help find a good point in the space in surprisingly few iterations.

Bayesian optimization was one of the tougher subjects to wrap my head around in graduate school, so I was very excited to see it get the Distill treatment.
Agnihotri and Batra explain the process through an analogy of picking the best places to dig for gold which, incidentally, was also one of its first real-world applications in the 1950s!
You can [read the full explainer here](https://distill.pub/2020/bayesian-optimization/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter); also check out [DragonFly](https://github.com/dragonfly/dragonfly?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and [BoTorch](https://botorch.org/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), two tools for automated Bayesian optimization [from my ML resources list](https://www.notion.so/adab36fecaea4306880898f41dcb9cb3?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=cb3a74562c914234ac171931dad6c2e4).

**Quick ML research + resource links** üéõ ([see all 63 resources](https://www.notion.so/adab36fecaea4306880898f41dcb9cb3?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=cb3a74562c914234ac171931dad6c2e4))

* ‚ö°Ô∏è Google‚Äôs People + AI Research (PAIR) group has [a set of open-source tools and platforms](https://pair.withgoogle.com/tools/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) ‚Äúthat make ML models more understandable, trustworthy, and fair,‚Äù including several model visualization and feature attribution projects.
* üèé [Microsoft released the second version](https://www.microsoft.com/en-us/research/blog/zero-2-deepspeed-shattering-barriers-of-deep-learning-speed-scale/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) of DeepSpeed and its Zero Redundancy Optimizer (ZeRO-2, see [DT #34](https://dynamicallytyped.com/issues/34-google-s-app-for-detecting-fake-news-memes-an-ai-for-logical-reasoning-and-microsoft-s-library-for-training-trillion-parameter-models-227577?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)). These improvements enable training models that are an order of magnitude larger and faster than previously possible: up to 170 billion parameters, at up to 10x previous state-of-the-art speeds. It‚Äôs open-source on GitHub at [microsoft/DeepSpeed](https://github.com/microsoft/DeepSpeed?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
* üì£ Google also proposed a new optimization technique: [speeding up neural network training with data echoing](https://ai.googleblog.com/2020/05/speeding-up-neural-network-training.html?m=1&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). It‚Äôs quite simple: while one bottlenecked part of the training pipeline is getting the next input ready, the current input gets ‚Äúechoed‚Äù through the rest of the model graph, reducing training time while preserving predictive performance. This is cool work, and hopefully it‚Äôll get upstreamed to TensorFlow for everyone to use.

## Artificial Intelligence for the Climate Crisis üåç

Just some quick links today.

**Quick climate AI links** üåç

* üõ¢ After tech companies came under fire a few months ago for their work with oil and gas companies, leading to the #techwontdrill it pledge (see [DT #33](https://dynamicallytyped.com/issues/33-billie-eilish-answers-ai-generated-interview-questions-visual-search-for-aerial-imagery-and-the-tech-won-t-drill-it-pledge-224742?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)), [Google has now committed that it will no longer enter into new agreements](https://onezero.medium.com/google-says-it-will-not-build-custom-a-i-for-oil-and-gas-extraction-72d1f71f42c8?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) to ‚Äúbuild custom AI/ML algorithms to facilitate upstream extraction in the oil and gas industry.‚Äù This information comes from [a new Greenpeace report](https://www.greenpeace.org/usa/reports/oil-in-the-cloud/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) which I‚Äôll cover in more detail in a future edition of DT.
* üåû Flo Wirtz of [Open Climate Fix](https://openclimatefix.org/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) wrote [an update](https://openclimatefix.org/blog/2020-05-07-update?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) on their solar PV [nowcasting](https://openclimatefix.org/projects/nowcasting?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) (how much electricity will be produced in the next few hours?) and [mapping](https://openclimatefix.org/blog/2019-07-09-solar-pv-mapping?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) (where are all solar panels located?) projects. Both projects hit quite a few proof points, including data acquisition and external validation; they also have a new co-funding award from the European Space Agency.

## Cool Things ‚ú®

![Pixel-me at graduation.](https://s3.amazonaws.com/revue/items/images/006/010/955/mail/049c822b1440924d19323a5ae1d0f531.png?1590243246)

_Pixel-me at graduation._

Japanese developer [Sato](https://twitter.com/sato_neet?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) released [pixel-me.tokyo](https://pixel-me.tokyo/en?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), a website that generates an 8-bit style portrait based on user-submitted photos.
It works both on human faces and pets.
Sato also previously made [AI Gahaku](https://ai-art.tokyo/en?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) (‚ÄúAI master painter‚Äù), which creates portraits in the style of classical painters.
He built both projects using pix2pix, a conditional generative adversarial network (cGAN) that‚Äôs commonly used for AI art projects.
Google developer advocate Kaz Sato (‚Äúsimilar names, but we are not the same person‚Äù) [wrote up a nice piece for the Google Cloud blog](https://cloud.google.com/blog/products/ai-machine-learning/using-google-cloud-platform-free-tier-to-scale-out-an-ai-service?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) about Sato‚Äôs process the projects.

**Quick cool things links ‚ú®**

* ü¶ë Job Talle used spiking neural networks and neuroevolution to [create digital squids that learn how to swim](https://jobtalle.com/neuroevolution_in_squids.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). Check out [the demo on his site](https://jobtalle.com/Cephalopods/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter); let it ‚Äúwarp‚Äù to about generation #1000 and then watch how the different squids learned (and failed to learn) to swim in different ways. I always think demos like this would be super cool to stylize and project on my wall as an ever-changing piece of art. One day.

**Thanks for reading!**
As usual, you can let me know what you thought of today‚Äôs issue using the buttons below or by replying to this email.
If you‚Äôre new here, check out the [Dynamically Typed archives](https://dynamicallytyped.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or subscribe below to get a new issues in your inbox every second Sunday.

**If you enjoyed this issue of Dynamically Typed, why not forward it to a friend?**
It‚Äôs by far the best thing you can do to help me grow this newsletter.
üå¨