---
title: "#27: Google&#x27;s Teachable Machine 2.0, OpenAI&#x27;s GPT-2 XL, and capturing solar energy with AI "
date: 2019-11-26
number: 27
aliases:
  - https://dynamicallytyped.com/issues/27-google-s-teachable-machine-2-0-openai-s-gpt-2-xl-and-capturing-solar-energy-with-ai-209719
---

Hey everyone!
It was bound to happen at some pointâ€”this is the first Dynamically Typed I havenâ€™t sent on time.
But with a good reason: I was in Edinburgh last weekend to receive my MSc Artificial Intelligence degree, and I spent all my time there with family and friends.
:)

Anyway, hereâ€™s what Iâ€™ve got for todayâ€™s edition.
On the productized AI side, Iâ€™m covering Googleâ€™s updated Teachable Machine tool; for ML research, thereâ€™s an update to OpenAIâ€™s staged GPT-2 release and a new reinforcement learning dataset with IKEA furniture.
For climate change AI, thereâ€™s Heliogenâ€™s computer vision-powered concentrated solar technology and CCAIâ€™s startup webinar; and for cool stuff I found a project thatâ€™s using neural networks to â€œunlockâ€ the contents of ancient Japanese documents.
Letâ€™s dive in!

## Productized Artificial Intelligence ğŸ”Œ

![Teachable Machine can be used to classify images, sounds, and poses.](https://s3.amazonaws.com/revue/items/images/005/259/075/mail/83ff0b71d1ed7dd84d6af925dc2f6016.png?1574757812)

_Teachable Machine can be used to classify images, sounds, and poses._

**Google launched Teachable Machine 2.0,** a web-based no-code tool for gathering data, training an AI model, testing and tweaking it, and deploying it to a website or app.
It can classify images (from files or a webcam), sounds (recorded from a microphone, with file support coming soon), and poses (from files or a webcam).
Hereâ€™s a few example projects from the Teachable Machine website:

> **Tiny Sorter:** A DIY experiment connecting Arduino and Teachable Machine.

> **Project Euphonia:** Steve Saling is using Teachable Machine to communicate in new ways, such as using facial gestures to trigger sounds.

> **Teachable Sorter:** A physical machine that you can teach to rapidly recognize and sort objects using your own custom machine learning models.

More:

* Kyle Phillips for Googleâ€™s The Keyword blog: [Teachable Machine 2.0 makes AI easier for everyone](https://www.blog.google/technology/ai/teachable-machine/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)
* Try it out yourself: [Teachable Machine](http://Teachable%20Machine)

## Machine Learning Research ğŸ›

!["[Full-size GPT-2] fed the opening line of neuromancer has created a novel premise i really want to read?" (@tambourine on Twitter.)](https://s3.amazonaws.com/revue/items/images/005/258/087/mail/daa1bc35477ab531e6075ac4d67920b2.jpeg?1574717202)

_"[Full-size GPT-2] fed the opening line of neuromancer has created a novel premise i really want to read?" (@tambourine on Twitter.)_

**OpenAI has finished the staged release of GPT-2 with their publication of the 1.5 billion-parameter model.**
GPT-2 is OpenAIâ€™s language model capable of generating text that convincingly looks like itâ€™s written by humans.
Out of fear for abuse, the lab has been releasing progressively bigger (and more capable) versions of the model slowly over the past nine monthsâ€”see my coverage of the initial 117M release ([DT #8](https://dynamicallytyped.com/issues/8-should-openai-open-source-their-impressive-new-language-model-161119?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)); the 345M release ([#13](https://dynamicallytyped.com/issues/13-caption-this-new-ai-powered-features-at-google-i-o-and-openai-s-staged-gpt-2-release-175669?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)); and the 774M release ([#22](https://dynamicallytyped.com/issues/22-mobile-apps-that-identify-plant-species-ai-powered-posture-correction-and-my-new-job-197292?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)).
OpenAIâ€™s five big takeaways from the release were the following:

> 1\.
> Humans find GPT-2 outputs convincing.

> 2\.
> GPT-2 can be fine-tuned for misuse.

> 3\.
> Detection is challenging.

> 4\.
> Weâ€™ve seen no strong evidence of misuse so far.

> 5\.
> We need standards for studying bias.

For details on each of these see [OpenAIâ€™s blog post](https://openai.com/blog/gpt-2-1-5b-release/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter#fnref2) from earlier this month.

In the weeks following the release, a lot of interesting work related to this full-size GPT-2 release popped up on Twitter.
Iâ€™ve compiled a few of them below:

* [Talk to Transformer](https://talktotransformer.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), which uses GPT-2 to generate some text based on a user-specified seed sentence (see [DT #13](https://dynamicallytyped.com/issues/13-caption-this-new-ai-powered-features-at-google-i-o-and-openai-s-staged-gpt-2-release-175669?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)), has been updated with the 1.5B model. (Link to [@tambourineâ€™s tweet](https://twitter.com/tambourine/status/1192297222714601474?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) from above.)
* [Hugging Face](https://huggingface.co/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) (an AI lab in NYC and Paris) has created a [GPT-2 Output Detector Demo](https://huggingface.co/openai-detector?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) that predicts whether a piece of text was generated using the model. It classified something I generated using Talk to Transformer as 99.47% fake. Pretty good.
* Another detector, wrapped in a [Firefox](https://addons.mozilla.org/en-US/firefox/addon/gptrue-or-false/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and [Chrome](https://chrome.google.com/webstore/detail/gptrue-or-false/bikcfchmnacmfhneafnpfekgfhckplfj?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) extension. Code on GitHub: [thesofakillers/GPTrue-or-False](https://github.com/thesofakillers/GPTrue-or-False?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
* Akshat Bubna wrote about fine-tuning GPT-2 for the Scale AI blog. Interesting read: [How to label 1M Data Points/Week](https://scale.com/blog/how-to-label-1m-data-points-week?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
* Jay Alammar wrote a really good visual explainer on how GPT-2 works: [The Illustrated GPT-2 (Visualizing Transformer Language Models)](https://jalammar.github.io/illustrated-gpt2/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

![Robots attempting to assemble IKEA furniture. (Lee et al.)](https://s3.amazonaws.com/revue/items/images/005/259/004/mail/a837680a079e756f93aa67bd38743ab6.jpeg?1574756783)

_Robots attempting to assemble IKEA furniture. (Lee et al.)_

**Thereâ€™s a fun new reinforcement learning environment for IKEA furniture assembly:**

> The IKEA Furniture Assembly Environment is one of the first benchmarks for testing and accelerating the automation of complex manipulation tasks.
> The environment is designed to advance reinforcement learning from simple toy tasks to complex tasks requiring both long-term planning and sophisticated low-level control.
> Our environment supports over 80 different furniture models, Sawyer and Baxter robot simulation, and domain randomization.

Each task in the environment can be observed as a camera view of the scene, a depth view, a segmentation view, and a goal view of the assembled piece of furniture.
A smaller beta version of the environment is currently available, with the full version set to launch next month.
More:

* Paper by Lee et al. (2019) on arXiv: [IKEA Furniture Assembly Environment for Long-Horizon Complex Manipulation Tasks](https://arxiv.org/abs/1911.07246?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)
* Code on GitHub: [clvrai/furniture](https://github.com/clvrai/furniture?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)

**Quick ML resource links âš¡ï¸** ([see all 48](https://www.notion.so/adab36fecaea4306880898f41dcb9cb3?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=cb3a74562c914234ac171931dad6c2e4))

* Cortex is an open source platform for deploying machine learning modelsâ€”trained with nearly any frameworkâ€”as production web services. GitHub link: [cortexlabs/cortex](https://github.com/cortexlabs/cortex?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)

## Artificial Intelligence for the Climate Crisis ğŸŒ

![One of Heliogen's concentrated solar power plants.](https://s3.amazonaws.com/revue/items/images/005/251/927/mail/4ebe7db0164bb076b1995e84332faf26.jpeg?1574605149)

_One of Heliogen's concentrated solar power plants._

**Heliogen is using artificial intelligence to increase the efficiency of concentrated solar power.**
Unlike the more common solar PV setups, where each panel converts sunlight to energy, concentrated solar power uses arrays of mirrors to concentrate sunlight on a single small point.
It then warms up a transport liquid to create a â€œsuper-heated systemâ€ that can be used to generate electricity or power industrial processesâ€”like steel and cement productionâ€”that require higher temperatures than other renewable energy sources can provide.

Concentrated solar power itself is not a new technology, but it has previously been expensive to use because of how precisely the mirrors had to be manufactured and installed.
Heliogenâ€™s AI approach removes the need for this costly precision:

> [To] address the calibration and control challenges of small heliostats, weâ€™ve developed and patented an innovative computer vision closed-loop tracking control system.
> This allows heliostats to be installed and manufactured in a relatively imprecise manner because the control system can detect and correct their actual tracking position in real-time during operation.

Heliogen has commercialized this HelioMax technology into two products: HelioHeat (heat up to 1500Â°C for industrial processes) and HelioFuel (green hydrogen production).
Their overall mission is to reduce our reliance on carbon-intensive energy sources by â€œreplacing fuels with sunlight.â€ Read more about Heliogen here:

* Heliogenâ€™s website: [heliogen.com](https://heliogen.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)
* Heliogenâ€™s blog post explaining concentrated solar and the role of computer vision in HelioMax: [Concentrated Solar and its Role in Solving Climate Change](https://heliogen.com/concentrated-solar-and-its-role-in-solving-climate-change/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)
* Matt Egan for CNN Business: [Secretive energy startup backed by Bill Gates achieves solar breakthrough](https://edition.cnn.com/2019/11/19/business/heliogen-solar-energy-bill-gates/index.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)

**Climate Change AI released a start-up webinar** co-sponsored by Better Ventures.
They pitch it as:

> A webinar for current and prospective entrepreneurs on commercializing innovations in the area of AI and climate change.
> Topics covered include funding milestones, early team formation, pitch deck structure, and fundraising best practices.

You can watch the full webinar on YouTube: [Start-up Webinar with Better Ventures and CCAI](https://www.youtube.com/watch?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=TCeBXxj5GUU).

## Cool Things âœ¨

![A page of Kuzushiji text transcribed by KuroNet.](https://s3.amazonaws.com/revue/items/images/005/259/158/mail/bb0f1f05379801ffe3e877453419d901.jpeg?1574759032)

_A page of Kuzushiji text transcribed by KuroNet._

**Machine learning is helping unlock millions of ancient Japanese documents written in Kuzushiji:**

> From 800 until 1900 CE, Japan used a writing system called Kuzushiji, which was removed from the curriculum in 1900 when the elementary school education was reformed.
> Currently, the overwhelming majority of Japanese speakers cannot read texts which are more than 150 years old.
> The volume of these textsâ€”comprised of over three million books in storage but only readable by a handful of specially-trained scholarsâ€”is staggering.

Alex Lamb wrote about his work with collaborators to create a KutoNet, a neural optical character recognition model to make these documents legible to more people.
The post digs into the challenges involved with transcribing Kuzushijiâ€”including the fact that most documents were created using artful woodblock printingâ€”and also covers the Kaggle competition they launched with their dataset.
Itâ€™s a cool read about the perhaps surprising application of AI to history.
Check it out over at The Gradient: [How Machine Learning Can Help Unlock the World of Ancient Japan](https://thegradient.pub/machine-learning-ancient-japan/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

**Thanks for reading!**
As usual, you can let me know what you thought of todayâ€™s issue using the buttons below or by replying to this email.
If youâ€™re new here, check out the [Dynamically Typed archives](https://dynamicallytyped.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or subscribe below to get a new issues in your inbox every second Sunday.

**If you enjoyed this issue of Dynamically Typed, why not forward it to a friend?**
Itâ€™s by far the best thing you can do to help me grow this newsletter.
ğŸ‘¨â€ğŸ“