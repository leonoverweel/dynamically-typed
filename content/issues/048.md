---
title: "#48: Microsoft&#x27;s deepfake detection app, the economics of AI startups, and 3x ML for climate change "
date: 2020-09-13
number: 48
aliases:
  - https://dynamicallytyped.com/issues/48-microsoft-s-deepfake-detection-app-the-economics-of-ai-startups-and-3x-ml-for-climate-change-274365
---

Hey everyone, welcome to Dynamically Typed #48.
Today‚Äôs newsletter is a bit later than usual because of an unexpected extra rowing training (yesterday) and an unexpected last beach day of the year (today) ‚Äî I‚Äôm trying to make the club‚Äôs eight and big ocean waves are fun!

I wrote today‚Äôs feature story on Video Authenticator, Microsoft‚Äôs new app for detecting deepfake videos.
Beyond that, I‚Äôve also got a new a16z essay on the economics of ML startups and some progress on under-display selfie cameras for productized AI.
For ML research, I found a useful guide for NLP data preparation and a not-so-BigGAN.
And finally, on the climate change AI side, I have a triplet of quick links that range from prevention (slash-and-burn detection in the Amazon) to adaptation (flood prediction in India and Bangladesh) to measurement (ice sheet thickness detection in glaciers).

## Productized Artificial Intelligence üîå

![](https://s3.amazonaws.com/revue/items/images/006/499/462/mail/1b6f5cdb2d383c1993c1d76546c3d679.png?1599928722)

[**Microsoft is launching Video Authenticator**](https://blogs.microsoft.com/on-the-issues/2020/09/01/disinformation-deepfakes-newsguard-video-authenticator/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) **, an app that helps organizations ‚Äúinvolved in the democratic process‚Äù detect deepfakes** ‚Äî videos that make people look like they‚Äôre saying things they‚Äôve never said by superimposing automatically-generated voice tracks and face movements over real videos.
Deepfakes are usually made using generative adversarial networks (GANs) like those in [Samsung AI‚Äôs neural avatars project](https://arxiv.org/abs/1905.08233?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) (see [DT #15](https://dynamicallytyped.com/issues/15-neural-avatars-ai-on-the-edge-and-apple-s-new-create-ml-app-180967?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) and in the popular open-source [DeepFaceLab app](https://github.com/iperov/DeepFaceLab?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

Because of all the obvious ways in which deepfakes can be abused, this has been a popular research area for technology platform companies: a bit over a year ago, Facebook launched their [deepfake detection challenge](https://ai.facebook.com/datasets/dfdc/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and Google contributed to TU Munich‚Äôs [FaceForensics benchmark](http://kaldir.vc.in.tum.de/faceforensics_benchmark/index.php?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) ([#23](https://dynamicallytyped.com/issues/23-robotic-raspberry-and-lettuce-pickers-2-5-billion-objects-in-pinterest-lens-and-an-analysis-of-the-ai-reproducibility-crisis-199555?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)).
Microsoft has now productized these research efforts with Video Authenticator.
The app checks photos and videos for the ‚Äúsubtle fading or greyscale elements‚Äù that may occur at a deepfake‚Äôs blending boundary ‚Äî where the fake facial movements mix in with the real background media ‚Äî and gives users a confidence score for whether a face is manipulated.
This happens in real-time and frame-by-frame for videos, which I imagine will be particularly useful for detecting subtle fakery, like a mostly-real video with a few small tweaks that change its message.

Video Authenticator initially won‚Äôt be made publicly available.
Instead, Microsoft is privately distributing it to news outlets, political campaigns, and media companies through the AI Foundation‚Äôs [Reality Defender 2020](https://rd2020.org/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) program, ‚Äúwhich will guide organizations through the limitations and ethical considerations inherent in any deepfake detection technology.‚Äù This makes sense, since deepfakes represent a typical cat-and-mouse AI security game ‚Äî new models will surely be trained specifically to fool Video Authenticator, which this limited release approach attempts to slow down.

I‚Äôd be interested to learn about how organizations integrate Video Authenticator into their existing workflows for validating the veracity of newsworthy videos.
I haven‚Äôt really come across any examples of big-name news organizations getting fooled by deepfakes yet, but I imagine it‚Äôs much more common on social media where videos aren‚Äôt vetted by journalists before being shared.

**Quick productized AI links üîå**

* üíº New must-read essay if you‚Äôre at an AI startup, by Martin Casado and Matt Bornstein at Andreesen Horowitz: [Taming the Tail: Adventures in Improving AI Economics](https://a16z.com/2020/08/12/taming-the-tail-adventures-in-improving-ai-economics/?utm_campaign=8a80fc1006-Benedict%27s%20newsletter%20free&utm_medium=email&utm_source=Benedict%27s%20Newsletter&utm_term=0_4999ca107f-8a80fc1006-70536657). ‚ÄúWe share some of the lessons, best practices, and earned secrets we learned through formal and informal conversations with dozens of leading machine learning teams. For the most part, these are their words ‚Äì not ours.‚Äù I couldn‚Äôt write a more convincing pitch for the post than that, so I didn‚Äôt try.
* üì± Not _quite_ productized yet, but an example of work I‚Äôm seeing more and more of on new arXiv uploads lately: [Deep Atrous Guided Filter for Image Restoration in Under Display Cameras](https://arxiv.org/abs/2008.06229?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) ‚Äî using AI to make photos taken _through_ phone screens look decent. The recent activity was probably due to the [RLQ ECCV challenge](https://rlq-tod.github.io?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) in August, but it‚Äôs making me wonder if in-display selfie cameras will go mainstream in the next year or two. ([Xiaomi is already hyping it up](https://www.androidcentral.com/heres-what-xiaomis-first-phone-display-selfie-camera-might-look?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).)

## Machine Learning Research üéõ

* ‚ö°Ô∏è [Data Readiness for Natural Language Processing](https://arxiv.org/abs/2009.02043?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) (Olsson and Sahlgren, 2020) is a detailed guide describing ‚Äúhow an organization may proceed to identify, make available, validate, and prepare data to facilitate automated analysis methods.‚Äù Nice link for your NLP toolbox!
* ‚úçÔ∏è When I covered BigGAN in February 2019 ([DT #6](https://dynamicallytyped.com/issues/6-deep-reinforcement-learning-from-an-atari-zoo-to-a-self-driving-car-in-20-minutes-155882?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)), its image generation results were very impressive ‚Äî but the model was also incredibly expensive to train, requiring a cluster of hundreds of TPUs. Now, just a year and a half later, [Han et al. (2020)](https://arxiv.org/abs/2009.04433?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) introduced not-so-BigGAN: close-enough image quality trained on just 4 Tesla-V100 GPUs ‚Äî an order of magnitude less compute. This speed of this progress is amazing.

_I‚Äôve also collected all 70+ ML research tools previously featured in Dynamically Typed_[ _on a Notion page_](https://www.notion.so/adab36fecaea4306880898f41dcb9cb3?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=cb3a74562c914234ac171931dad6c2e4) _for quick reference.
‚ö°Ô∏è_

## Artificial Intelligence for the Climate Crisis üåç

* üî• AmazonNET by [Mohla et al. (2020)](https://arxiv.org/abs/2009.04634?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is new a model that detects and segments rainforest burn marks due to wildfires from satellite imagery. Slash-and-burn is a popular technique for clearing away large swaths of the Amazon rainforest for farming use, which additionally is a common cause of wildfires in the region. Detecting and controlling these fires from the ground is difficult, so this is very important work: automated segmentation of these burn scars will allow for more complete and objective tracking, and for more effective prevention. The most interesting contribution here is that the proposed model learns from a dataset with very noisy labels.
* üåä Yossi Matias wrote about Google‚Äôs progress on [flood forecasting in India and Bangladesh](https://blog.google/technology/ai/flood-forecasts-india-bangladesh/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) for the company‚Äôs The Keyword blog. They‚Äôre now covering an area of 250,000 square kilometers with a population of 200 million people ‚Äî a 20x increase from last year ‚Äî to whom Google has sent 30 million river flood warning notifications in total so far. The [technical write-up](https://ai.googleblog.com/2020/09/the-technology-behind-our-recent.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) by Sella Nevo contains details of the AI that went into this, such as a model to infer elevation levels from satellite imagery and a multi-stage model to estimate river profiles. Where AmazonNET helps with climate change prevention, this work sits solidly on the adaptation side.
* üßä And finally, on the climate measurement side: [Rahnemoonfar et al. (2020)](https://arxiv.org/abs/2009.00191?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) introduced a new convolutional network that can detect ‚Äî and quite successfully estimate the thickness of ‚Äî different ice layers inside glaciers and ice sheets. Deep learning for science!

**Thanks for reading!**
As usual, you can let me know what you thought of today‚Äôs issue using the buttons below or by replying to this email.
If you‚Äôre new here, check out the [Dynamically Typed archives](https://dynamicallytyped.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or subscribe below to get a new issues in your inbox every second Sunday.

**If you enjoyed this issue of Dynamically Typed, why not forward it to a friend?**
It‚Äôs by far the best thing you can do to help me grow this newsletter.
üìì