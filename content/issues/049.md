---
title: "#49: Movement in autonomous trucking, Microsoft&#x27;s DeepSpeed update, and Transformers as Graph Neural Networks "
date: 2020-09-27
number: 49
aliases:
  - https://dynamicallytyped.com/issues/49-movement-in-autonomous-trucking-microsoft-s-deepspeed-update-and-transformers-as-graph-neural-networks-277883
---

Hey everyone, welcome to Dynamically Typed #49!
Today‚Äôs productized AI feature story is on autonomous trucks, which is where I think self-driving vehicle tech will have its first big impact; I‚Äôve also got quick links to Facebook‚Äôs survey paper on AI systems for social network safety; and an ECCV workshop on fair facial recognition systems (spoiler: they‚Äôre still not fair).

For ML research, there‚Äôs an update to Microsoft‚Äôs DeepSpeed training library; an essay that frames Transformers as Graph Neural Networks; a paper on how researcher experience impacts model performance; and the release of the NumPy paper!
Finally, for climate change AI I found a tree planting location recommender system for reforestation; and for cool stuff there‚Äôs a new bioinformatics paper that can reconstruct images of what your eyes are seeing based on a scan of your brain.

## Productized Artificial Intelligence üîå

**Autonomous trucking is where I think self-driving vehicle technology will have its first big impact** , much before e.g.
the taxi or ride sharing industries.
Long-distance highway truck driving ‚Äî with hubs at city borders where human drivers take over ‚Äî is a much simpler problem to solve than inner-city taxi driving.
Beyond the obvious lower complexity of not having to deal with traffic lights, small streets and pedestrians, a specific highway route between two high-value hubs can also be mapped in high detail much more economically than an ever-changing city center could.
And, of course, self-driving trucks won‚Äôt have the 11-hour-per-day driving safety limit imposed on human drivers.
This all makes for quite an attractive pitch when taken together.

In recent news, [Jennifer Smith at the Wall Street Journal reported](https://www.wsj.com/articles/robot-trucks-are-seeking-inroads-into-freight-business-11598954400?redirect=amp&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter#click=https://t.co/FHbnibCvDc) that startup [Ike Robotics](https://www.ike.com?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) has reservations for its first 1,000 heavy-duty autonomous trucks, from ‚Äútransport operators Ryder System Inc., NFI Industries Inc.
and the U.S.
supply-chain arm of German logistics giant Deutsche Post AG.‚Äù

> Tapping into big carriers‚Äô logistics networks and operational expertise means Ike can focus on the technology piece‚Äîsystems engineering, safety and technical challenges such as computer vision‚Äîsaid Chief Executive Alden Woodrow.

> ‚ÄúThey are going to help us make sure we build the right product, and we are going to help them prepare to adopt it and be successful,‚Äù said Mr.
> Woodrow, who worked on self-driving trucks at Uber Technologies Inc.
> before co-founding Ike in 2018.

Unlike rival startups, Ike wants to be a software-as-a-service provider of self-driving tech for existing logistics operators, instead of becoming one themselves.
It‚Äôll be interesting to see how well this business model works out when competitors start offering a similar service ‚Äî the biggest question is how easy or hard it‚Äôll be for an operator to swap one self-driving SaaS out for another.
If it‚Äôs easy, that‚Äôll make for a very competitive space.

(On the disruption side: there are nearly 3 million truck drivers in the United States alone, so widespread automation here can be quite impactful.
Until today, I thought trucking was the biggest profession in most US states because of [this 2015 NPR article](https://www.npr.org/sections/money/2015/02/05/382664837/map-the-most-common-job-in-every-state?t=1601202508006&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), but apparently that was [based on wrongly interpreted statistics](https://www.marketwatch.com/story/no-truck-driver-isnt-the-most-common-job-in-your-state-2015-02-12?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter); the most common job is in retail ‚Äî no surprise there.
Nonetheless, trucking is currently a major profession.
A decade from now it may no longer be.)

**Quick productized AI links üîå**

* üõ°Facebook is increasingly talking publicly about the work it does to keep its platform safe, probably at least partially in response to the constant stream of news about its failures in this area (from [Myanmar](https://www.nytimes.com/2018/10/15/technology/myanmar-facebook-genocide.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) to [Plandemic](https://www.getrevue.co/profile/caseynewton/issues/how-plandemic-went-viral-247102?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)). This does mean we get to learn a lot about the systems that Facebook AI Research (FAIR) is building to stop viral hoaxes before they spread too widely. Examples include the recent inside look into their AI Red Team ([DT #47](https://dynamicallytyped.com/issues/47-facebook-s-ai-red-team-predictions-of-future-ai-crimes-and-tensorflow-s-new-tf-coder-tool-271283?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)); their Web-Enabled Simulations (WES, [#38](https://dynamicallytyped.com/issues/38-gender-bias-reductions-in-google-translate-facebook-s-bot-simulation-and-ml-based-detection-of-battery-degradation-240063?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) and Tempotal Interaction Embeddings (TIES, [#34](https://dynamicallytyped.com/issues/34-google-s-app-for-detecting-fake-news-memes-an-ai-for-logical-reasoning-and-microsoft-s-library-for-training-trillion-parameter-models-227577?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) for detecting bots on Facebook; and their DeepFake detection dataset ([#23](https://dynamicallytyped.com/issues/23-robotic-raspberry-and-lettuce-pickers-2-5-billion-objects-in-pinterest-lens-and-an-analysis-of-the-ai-reproducibility-crisis-199555?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)). Now, [Halevy et al. (2020)](https://arxiv.org/abs/2009.10311?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) have published [an extensive survey on their work preserving integrity in online social networks](https://arxiv.org/pdf/2009.10311.pdf?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), in which they ‚Äúhighlight the techniques that have been proven useful in practice and that deserve additional attention from the academic community.‚Äù It covers many of the aforementioned topics, plus a lot more.
* üë®‚Äçü¶± Your weekly reminder that anyone who tries to sell you a facial recognition system without any age, gender, racial or accessory biases, probably does not actually have such a system to sell to you. From the 1800 submissions to the FairFace Challenge at ECCV 2020, [Sixta et al. (2020)](https://arxiv.org/abs/2009.07838?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) found that: ‚Äú[the] top-10 teams [show] higher false positive rates (and lower false negative rates) for females with dark skin tone as well as the potential of eyeglasses and young age to increase the false positive rates too.‚Äù I really hope that everyone deploying these systems widely is aware of this and the potential consequences.

## Machine Learning Research üéõ

* üèé Microsoft has updated [DeepSpeed](https://github.com/microsoft/DeepSpeed?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), its open-source library for efficiently training massive ML models (see [DT #34](https://dynamicallytyped.com/issues/34-google-s-app-for-detecting-fake-news-memes-an-ai-for-logical-reasoning-and-microsoft-s-library-for-training-trillion-parameter-models-227577?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [#40](https://dynamicallytyped.com/issues/40-pinterest-s-ml-for-board-organization-gan-aided-pixel-art-and-bayesian-optimization-gets-the-distill-treatment-247582?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)), with [four big improvements](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter): [3D parallelism](http://%20https//www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter#toc-heading-0) for training trillion-parameter models; [ZeRO-Offload](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter#toc-heading-3) for 10x bigger model training on a single GPU; [Sparse Attention](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter#toc-heading-4) kernels for 10x longer input sequences in Transformers; and [1-bit Adam](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter#toc-heading-5) for reducing network load in multi-GPU training. My work focuses on tiny models rather than large ones, so I haven‚Äôt gotten a chance to try DeepSpeed, but if any of you have, I‚Äôd love to hear about your experience!
* üåê Chaitanya K. Joshi wrote an essay for The Gradient where he argues that [Transformers are Graph Neural Networks](https://thegradient.pub/transformers-are-graph-neural-networks/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), equating the former‚Äôs attention mechanism to the latter‚Äôs aggregation functions. It‚Äôs a great introduction to both model types, and Joshi poses that these two subfields of machine learning can learn a lot from each other. (Also, he represents nodes in a GNN using emojis instead of letters, and references them as such in the text, which I love.) Great weekend read.
* üë©‚Äçüî¨ We‚Äôve seen ‚Äútuning hyperparameters without grad students‚Äù with [Dragonfly](https://github.com/dragonfly/dragonfly?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) ([DT #11](https://dynamicallytyped.com/issues/11-adobe-and-google-s-new-video-ai-tools-stanford-s-hype-for-gans-and-a-conversation-with-books-170283?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) but‚Ä¶ how much does a researcher‚Äôs experience actually correlate with their skills for tuning an ML model? [Anand et al, (2020)](https://arxiv.org/abs/2008.05981?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) investigated this and found a strong positive correlation between experience and final model accuracy, and ‚Äúthat an experienced participant finds better solutions using fewer resources on average.‚Äù Glad to see my skills aren‚Äôt yet completely automatable yet! (The paper is co-authored by [Jan van Gemert](https://jvgemert.github.io?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), who was the first person to explain to me what a convolution is, in a guest lecture during my first year of undergrad. üòä)
* üßÆ The NumPy paper is out! It‚Äôs a Nature article by [Harris et al. (2020)](https://www.nature.com/articles/s41586-020-2649-2?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). Is this going to break records in citation counts, as pretty much every machine learning paper should probably be referencing it? Either way, I‚Äôve [updated](https://github.com/leonoverweel/bibtex-python-package-citations/commit/b860b032d532a6732a47d1cfd3729a73516f0aba?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) my [repo of BibTex citations for Python packages](https://github.com/leonoverweel/bibtex-python-package-citations?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) to add it.

_I‚Äôve also collected all 70+ ML research tools previously featured in Dynamically Typed_[ _on a Notion page_](https://www.notion.so/adab36fecaea4306880898f41dcb9cb3?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=cb3a74562c914234ac171931dad6c2e4) _for quick reference.
‚ö°Ô∏è_

## Artificial Intelligence for the Climate Crisis üåç

* üå≥ [Rana and Vashney (2020)](https://arxiv.org/abs/2009.08002?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) developed ePSA (e-Plantation Site Assistant), a recommender system that ‚Äúcombines physics-based/traditional forestry science knowledge with machine learning‚Äù to find the optimal spots to plant trees when reforesting an area. The ML portion is an XGBoost decision tree ensemble to calculate deforestation probabilities based on historical data. After testing the system around northern India, they found that ‚Äúin 26 out of 30 locations, forest officials found the recommendations of the app very useful for selecting the right site for planting trees.‚Äù

## Cool Things ‚ú®

![Images shown to subjects (first column) vs. images reconstructed purely from a brain scan (third column, red). (Gaziv et al., 2020)](https://s3.amazonaws.com/revue/items/images/006/566/715/mail/d24fd377b82d5090432f82b7aab08477.png?1601207902)

_Images shown to subjects (first column) vs. images reconstructed purely from a brain scan (third column, red). (Gaziv et al., 2020)_

Today in cool stuff that‚Äôs much further along than I thought it was: [Gaziv et al.
(2020)](https://www.biorxiv.org/content/10.1101/2020.09.06.284794v1?rss=1&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) developed a self-supervised approach to fMRI-too-image reconstruction ‚Äî **generating pictures of what your eyes are seeing from a brain scan**.
Their main contribution is this self-supervised aspect: they pretrain their decoder on unlabeled ImageNet data, of which there is much more available than the fMRI-image pairs that previous work exclusively used.

Their results are good enough for a human to recognize e.g.
a glass of beer or an animal (see above), which were reconstructed from fMRIs without having been in either the pretraining or fMRI datasets!
Check out Figures 1 and 2 in the [PDF on bioRxiv](https://www.biorxiv.org/content/10.1101/2020.09.06.284794v1.full.pdf?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) for more examples.

**Thanks for reading!**
As usual, you can let me know what you thought of today‚Äôs issue using the buttons below or by replying to this email.
If you‚Äôre new here, check out the [Dynamically Typed archives](https://dynamicallytyped.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or subscribe below to get a new issues in your inbox every second Sunday.

**If you enjoyed this issue of Dynamically Typed, why not forward it to a friend?**
It‚Äôs by far the best thing you can do to help me grow this newsletter.
üìì