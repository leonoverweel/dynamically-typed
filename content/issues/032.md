---
title: "#32: Google&#x27;s chatbot gets punny, GitHub finds good first issues, and Tinder targets toxicity "
date: 2020-02-02
number: 32
aliases:
  - https://dynamicallytyped.com/issues/32-google-s-chatbot-gets-punny-github-finds-good-first-issues-and-tinder-targets-toxicity-221958
---

Hey everyone, welcome to Dynamically Typed #32!
We‚Äôve hit another base-2 milestone: this is edition number 2‚Åµ; the previous one, 2‚Å¥ ([DT #16](https://dynamicallytyped.com/issues/16-finding-whales-with-ai-and-97-pages-of-ml-for-climate-change-183400?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)), came out last summer when I had just moved to Amsterdam; and the next one, 2‚Å∂, will be in April 2021.
ü§ì

Here‚Äôs what I have for you in today‚Äôs newsletter.
For productized AI, I‚Äôm covering GitHub‚Äôs new AI-powered _good first issues_ feature, as well as the different ways social media companies are using AI to combat toxicity on their platforms.
For ML research, there‚Äôs Google‚Äôs new Meena chatbot, an economics perspective on AI research, and an author‚Äôs thoughts on writing for Distill.
Finally, for climate AI, there seems to be a big influx of venture capital money in Silicon Valley.
Happy reading!

## Productized Artificial Intelligence üîå

![Documentation fixes are a common example of "good first issues," as indicated by the purple tag on this issue on the Larq repository. (Larq is the open-source BNN training library I work on at Plumerai.)](https://s3.amazonaws.com/revue/items/images/005/502/968/mail/5877d45299053d94ba1e5a7f26cb0fed.png?1580586123)

_Documentation fixes are a common example of "good first issues," as indicated by the purple tag on this issue on the Larq repository. (Larq is the open-source BNN training library I work on at Plumerai.)_

**Tiferet Gazit wrote about how GitHub made its AI-powered _good first issue_ feature.**
GitHub is an online platform for collaborating on open- (and closed-) source codebases, where users can write _issues_ to notify repository maintainers of bugs or desired features in their software projects.
Maintainers can label low-hanging fruit issues‚Äîlike documentation updates, error reporting fixes, or output formatting bugs‚Äîas __ a _good first issue_ that new contributors can tackle to familiarize themselves with the project‚Äôs codebase.

GitHub recently [launched a feature](https://github.blog/2020-01-22-browse-good-first-issues-to-start-contributing-to-open-source/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) that automatically detects such good first issues in open-source codebases.
Initially it worked by just looking for (synonyms of) the _good-first-issue_ or _documentation_ tags set manually by repository maintainers, but that did not yield enough issues for GitHub‚Äôs social news feed:

> Relying on these labels, however, means that only about 40 percent of the repositories we recommend have easy issues we can surface.
> Moreover, it leaves maintainers with the burden of triaging and labeling issues.
> Instead of relying on maintainers to manually label their issues, we wanted to use machine learning to broaden the set of issues we could surface.

That‚Äôs where deep learning comes in: GitHub used this initial sample of good first issues detected based on explicitly-set labels as training data for a natural language classifier that predicts whether an issue qualifies as good first issue based on its title and body text.
With this new model, which gets run on all new open-source issues once a day, GitHub is now ‚Äúable to surface issues in about 70 percent of repositories we recommend to users"‚Äîa big improvement!

Gazit‚Äôs blog post on the feature goes in depth on a lot of technical details, including data pre-processing/denoising, the deployment setup, and the coverage vs.
accuracy tradeoff, that we know typically take much more time on a productized AI project than the actual model creation and training do.
It‚Äôs great to see these aspects being highlighted.
Read the full post on _The GitHub Blog:_ [How we built the good first issues feature](https://github.blog/2020-01-22-how-we-built-good-first-issues/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

**Quick productized AI links üîå**

* üí¨ To combat the low reporting rates of the harassment happening on its platform, **Tinder is now using artificial intelligence to detect potentially toxic chat messages** and ask users whether they want to report the sender. An interesting challenge here is that the preceding conversation‚Äîor lack thereof‚Äîhas a big effect on whether a message comes across a flirty or creepy. The number of reported chats increased by 37% after the feature launched. Arielle Pardes for _WIRED_ : [Tinder Asks ‚ÄòDoes This Bother You‚Äô?](https://www.wired.com/story/tinder-does-this-bother-you-harassment-tools/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)
* ü§¨ Related: **Instagram and Twitter are also using AI to detect potential bullying and hateful content as users write it,** and ask them whether they‚Äôre sure they want to post it. Sara Harrison for _WIRED_ : [Twitter and Instagram Unveil New Ways to Combat Hate‚ÄîAgain](https://www.wired.com/story/twitter-instagram-unveil-new-ways-combat-hate-again/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)

## Machine Learning Research üéõ

!["Meena executes a multi-turn joke in an open-domain setting. We were unable to find this in the data." (Adiwardana et al., 2020)](https://s3.amazonaws.com/revue/items/images/005/504/543/mail/93dd707e559f2f275db6853d186f61be.png?1580643889)

_"Meena executes a multi-turn joke in an open-domain setting. We were unable to find this in the data." (Adiwardana et al., 2020)_

**Google AI has a new open-domain chatbot: Meena.**
It‚Äôs based on one encoder and thirteen decoder networks, constructed from neural architecture search-discovered [evolved transformer](https://ai.googleblog.com/2019/06/applying-automl-to-transformer.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) blocks, and, like los of modern natural language processing/generation research, the model behind Meena is _gargantuan_ :

> The Meena model has 2.6 billion parameters and is trained on 341 GB of text, filtered from public domain social media conversations.
> Compared to an existing state-of-the-art generative model, OpenAI GPT-2 [see [DT #8](https://dynamicallytyped.com/issues/8-should-openai-open-source-their-impressive-new-language-model-161119?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [#13](https://dynamicallytyped.com/issues/13-caption-this-new-ai-powered-features-at-google-i-o-and-openai-s-staged-gpt-2-release-175669?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [#22](https://dynamicallytyped.com/issues/22-mobile-apps-that-identify-plant-species-ai-powered-posture-correction-and-my-new-job-197292?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [#27](https://dynamicallytyped.com/issues/27-google-s-teachable-machine-2-0-openai-s-gpt-2-xl-and-capturing-solar-energy-with-ai-209719?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [#28](https://dynamicallytyped.com/issues/28-ocr-for-latex-equations-night-sight-for-astrophotography-and-a-gpt-2-powered-text-adventure-212704?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)], Meena has 1.7x greater model capacity and was trained on 8.5x more data.

Although the model is trained on the standard automated _perplexity_ metric‚Äîwhich intuitively ‚Äúrepresents the number of choices the model is trying to choose from when producing the next token"‚Äîthe authors introduce a new human evaluation metric to assess their model.
The new metric asks reviewers to rate a bot‚Äôs responses on _sensibleness_ (Does this response make sense in the context of the preceding conversation?) and _specificity_ (Is this not something generic like "haha‚Äù or ‚Äúthat‚Äôs nice‚Äù you could reply in lots of situations?), and _averages_ them.
Under this SSA metric, Meena scores 79%, compared to 86% for human conversations and 56% for the next-best competing chatbot.

One cool thing that drew me to this work: they preprocess their data for neural network consumption using byte-pair encoding (BPE) by [Sennrich et al.
(2016)](https://arxiv.org/abs/1508.07909?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)‚Äîwho was one of my professors in Edinburgh, for the (quite a mouthful) _natural language processing, generation, and machine translation_ course!

Read more about Meena here:

* _Google AI Blog_ post by Daniel Adiwardana and Thang Luong: [Towards a Conversational Agent that Can Chat About‚Ä¶Anything](https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)
* Paper on arXiv: [Adiwardana et al. (2020)](https://arxiv.org/abs/2001.09977?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)

**Quick ML research + resource links** üéõ ([see all 51 resources](https://www.notion.so/adab36fecaea4306880898f41dcb9cb3?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=cb3a74562c914234ac171931dad6c2e4))

* üë®‚Äçüî¨ Sam Greydanus wrote an author‚Äôs-perspective retrospective with his experience with writing for [Distill](https://distill.pub?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), the machine learning publication that focuses on ‚Äúthe science of deep learning.‚Äù Lots of interesting insights for people (like yours truly) who hope to one day write an article for Distill. Read it on Greydanus‚Äô personal blog: [Distill Article: The Paths Perspective on Value Learning](https://greydanus.github.io/2020/01/27/paths-perspective/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
* üí∏ Juan Mateos-Garcia wrote an overview of papers presented at the third edition of the [Economics of Artificial Intelligence conference](http://conference.nber.org/sched/AIf19?show_participants=1&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), which happened in September 2019. Always interesting to see another field‚Äôs perspective of the developments in our field. Check it out on _The Gradient:_ [The Economics of AI Today](https://thegradient.pub/the-economics-of-ai-today/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
* ‚ö°Ô∏è Software Engineering for AI/ML‚Äîan annotated bibliography ([ckaestne/seabib](https://github.com/ckaestne/seaibib?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) by Christian K√§stner at CMU, covering testing debugging, data management, reproducibility, etc.

## Artificial Intelligence for the Climate Crisis üåç

I didn‚Äôt find any new climate change AI projects that have progressed far enough to cover in the newsletter for this edition.
However, there is still lots of exciting stuff happening in the space.

I‚Äôve started listening to [Jason Jacobs](https://twitter.com/jjacobs22?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)‚Äô [_My Climate Journey_ podcast](https://twitter.com/mcjpod?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), which I‚Äôve really enjoyed so far.
It‚Äôs been great to hear what climate challenges lots of different industries are dealing with (beyond the obvious ones like energy and transportation), and to start thinking about how AI/ML might be relevant there.

It also looks like more and more of Silicon Valley is warming up (ha) to working on climate-related problems.
On Twitter these past two weeks, [Ravi Mikkelsen](https://twitter.com/RaviMikkelsen?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [Katie Fehrenbacher](https://twitter.com/katiefehren/status/1223395672386240514?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [Ann Bordetsky](https://twitter.com/annbordetsky/status/1222692424960471040?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), and again [Jason Jacobs](https://twitter.com/jjacobs22/status/1222688774708236288?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) have been talking about the surge of venture capital investments into climate tech.
(And [away from crypto](https://twitter.com/jjacobs22/status/1223817147924783106?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).) Hopefully, this means we‚Äôll only start to see more and more climate change AI companies and products over the next few years!

**Quick climate AI links** üåç

* ‚òÅÔ∏è [Cumulo](https://arxiv.org/abs/1911.04227?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is a new ‚Äúbenchmark dataset for training and evaluating global cloud classification models.‚Äù Understanding cloud types, formations, and movements will be key for things like solar power output prediction (mitigation) but also for identifying severe weather events (adaptation).

**Thanks for reading!**
As usual, you can let me know what you thought of today‚Äôs issue using the buttons below or by replying to this email.
If you‚Äôre new here, check out the [Dynamically Typed archives](https://dynamicallytyped.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or subscribe below to get a new issues in your inbox every second Sunday.

**If you enjoyed this issue of Dynamically Typed, why not forward it to a friend?**
It‚Äôs by far the best thing you can do to help me grow this newsletter.
ü¶Ü