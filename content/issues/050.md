---
title: "#50: Microsoft exclusively licenses OpenAI&#x27;s GPT-3, Amsterdam&#x27;s AI registry, and cloud nowcasting progress "
date: 2020-10-11
number: 50
aliases:
  - /issues/50-microsoft-exclusively-licenses-openai-s-gpt-3-amsterdam-s-ai-registry-and-cloud-nowcasting-progress-281394
---

Hey everyone, welcome to the 50th (üéâ) edition of Dynamically Typed!

One of the things I‚Äôm most proud of with this newsletter is that it‚Äôs allowed me to build a big corpus of my own previous writing to refer back to.
A while ago, I wrote [a Python script](https://github.com/leonoverweel/dynamically-typed/blob/master/revue_to_hugo.py?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) to download DT issues into a [repository of markdown files](https://github.com/leonoverweel/dynamically-typed/tree/master/content/issues?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
Now that this repository has grown into 50 issues going back almost two years, I find myself searching through it several times a week and rediscovering tools, articles, or papers.
It‚Äôs also super useful for finding connections like the one between GPT-3 and DeepSpeed from the first story below.
(And I‚Äôm using it for another new project coming soon ‚Äî stay tuned!)

Anyway, enough of that: let‚Äôs get into the last two weeks of productized AI, ML research, climate AI, and cool stuff.

In today‚Äôs issue, I wrote a Productized AI story on Microsoft‚Äôs exclusive license of OpenAI‚Äôs GPT-3 model and what this may tell us about their future relationship; I also have a link to Amsterdam‚Äôs and Helsinki‚Äôs new AI algorithm registries.
For ML research, I‚Äôve got quick links to the new Papers with Code feature on arXiv, Black in AI‚Äôs new academic program, a tool called TensorSensor, and a new Transformers paper that‚Äôs making the rounds on Twitter.
I found some recent cloud nowcasting work for climate AI.
And, finally, for cool stuff I have links to a short story about AI scooters, and NVIDIA‚Äôs new Imaginaire library.

## Productized Artificial Intelligence üîå

![](https://s3.amazonaws.com/revue/items/images/006/633/129/mail/21d2ff8f0bae6f095178ef6386589964.jpeg?1602274609)

**OpenAI is exclusively licensing GPT-3 to Microsoft.
What does this mean for their future relationship?**

GPT-3 is OpenAI‚Äôs latest gargantuan language model (see [DT #42](https://dynamicallytyped.com/issues/42-facial-recognition-exodus-openai-s-new-gpt-3-language-model-and-oil-in-the-cloud-254772?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) that‚Äôs uniquely capable of performing many different ‚Äútext-in, text-out‚Äù tasks ‚Äî demos range from imitating famous writers to generating code ([#44](https://dynamicallytyped.com/issues/44-one-month-in-gpt-3-powered-openai-api-demos-take-the-web-by-storm-261577?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) ‚Äî without needing to be fine-tuned: its crazy scale makes it [a few-shot learner](https://arxiv.org/abs/2005.14165?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

In July 2019, OpenAI announced it got a $1 billion investment from Microsoft.
Back then, this raised some eyebrows in the (academic) machine learning community, which can sometimes be a bit allergic to the commercialization of AI ([#19](https://dynamicallytyped.com/issues/19-microsoft-s-1b-openai-investment-lyft-s-dataset-and-what-makes-a-peacock-a-peacock-190545?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)).
The exact terms of the investment were never disclosed, but some key elements of the deal were.
[Tom Simonite for WIRED](https://twitter.com/tsimonite/status/1153340994986766336?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter):

> Most interesting bit of the OpenAI announcement: ‚Äúwe intend to license some of our pre-AGI technologies, with Microsoft becoming our preferred partner.‚Äù

Now, a year and a bit later, that‚Äôs exactly what happened.
From the [OpenAI blog](https://openai.com/blog/openai-licenses-gpt-3-technology-to-microsoft/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter):

> In addition to offering GPT-3 and future models via the OpenAI API, and as part of a multiyear partnership announced last year, OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.

What does that mean?
[Nick Statt for The Verge](https://www.theverge.com/2020/9/22/21451283/microsoft-openai-gpt-3-exclusive-license-ai-language-research?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter):

> A Microsoft spokesperson tells _The Verge_ that its exclusive license gives it unique access to the underlying code of GPT-3, which contains technical advancements it hopes to integrate into its products and services.

In their [blog post](https://blogs.microsoft.com/blog/2020/09/22/microsoft-teams-up-with-openai-to-exclusively-license-gpt-3-language-model/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), Microsoft pitches this as a way to ‚Äúexpand [their] Azure-powered AI platform in a way that democratizes AI technology,‚Äù to which the community again[ reacted negatively](https://thegradient.pub/ai-democratization-in-the-era-of-gpt-3/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter): if you want to democratize AI, why not just open-source GPT-3‚Äôs code and training data?* I agree that ‚Äúdemocratizing‚Äù is a bit of a stretch, but I think there‚Äôs a much more interesting discussion to be had here than the one on a self-congratulatory word choice in a corporate press release.
Perhaps ironically, that discussion also starts from overanalyzing another few words in that very same press release.

According to Microsoft‚Äôs blog post about the licensing deal, GPT-3 ‚Äúis trained on Azure‚Äôs AI supercomputer.‚Äù I wonder if that means OpenAI is now using Microsoft‚Äôs open-source [DeepSpeed library](https://github.com/microsoft/DeepSpeed?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) ([#34](https://dynamicallytyped.com/issues/34-google-s-app-for-detecting-fake-news-memes-an-ai-for-logical-reasoning-and-microsoft-s-library-for-training-trillion-parameter-models-227577?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) to train its GPT models.
DeepSpeed is a library for distributed training of enormous ML models that has specific features to support training large Transformers; Microsoft Research claimed in May that it‚Äôs capable of training models with up to 170 billion parameters ([#40](https://dynamicallytyped.com/issues/40-pinterest-s-ml-for-board-organization-gan-aided-pixel-art-and-bayesian-optimization-gets-the-distill-treatment-247582?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)).
GPT-3 is a 175-billion-parameter Transformer that was released in June, just one month later.
That seems unlikely to be a coincidence, and Microsoft‚Äôs [latest DeepSpeed update](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) ([#49](https://dynamicallytyped.com/issues/49-movement-in-autonomous-trucking-microsoft-s-deepspeed-update-and-transformers-as-graph-neural-networks-277883?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) even includes some experimental work using the GPT-3 architecture.

So this suggests that the partnership goes beyond just the exchange of Microsoft‚Äôs money and compute for OpenAI‚Äôs trained models and ML brand strength (an exchange of cloud for clout, if you will) that we [previously expected](https://twitter.com/soumithchintala/status/1153308199610511360/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
Are the companies actually also deeply collaborating on ML and systems engineering research?
I‚Äôd love to find out.

If so, this could be an early indication that Microsoft ‚Äî who I‚Äôm sure is at least a little bit envious of Google‚Äôs ownership of DeepMind ‚Äî will eventually want to acquire OpenAI.
And it could be a great fit.
Looking at Microsoft‚Äôs recent acquisition history, it has so far let GitHub (which it acquired two years ago) continue to operate largely autonomously.
This makes it an attractive potential parent company for OpenAI: the lab probably wouldn‚Äôt have to give up too much of its independence under Microsoft‚Äôs stewardship.
So unless OpenAI actually invents and monetizes some form of artificial general intelligence (AGI) in the next five to ten years ‚Äî which I don‚Äôt think they will ‚Äî I wouldn‚Äôt be surprised if they end up becoming Microsoft‚Äôs DeepMind.

* One big reason for not open-sourcing GPT-3‚Äôs code and data is security; see my coverage of OpenAI‚Äôs staged release strategy for GPT-2 ([#8](https://dynamicallytyped.com/issues/8-should-openai-open-source-their-impressive-new-language-model-161119?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [#13](http://%20http://dynamicallytyped.com/issues/13-caption-this-new-ai-powered-features-at-google-i-o-and-openai-s-staged-gpt-2-release-175669), [#22](https://dynamicallytyped.com/issues/22-mobile-apps-that-identify-plant-species-ai-powered-posture-correction-and-my-new-job-197292?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [#27](https://dynamicallytyped.com/issues/27-google-s-teachable-machine-2-0-openai-s-gpt-2-xl-and-capturing-solar-energy-with-ai-209719?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)).

**Quick productized AI links üîå**

* üóÇ Amsterdam (where I live!) and Helsinki (where I don‚Äôt live) have launched their ‚ÄúAI algorithm registries.‚Äù These are actually a pretty cool idea: whenever a municipalities ‚Äúutilizes algorithmic systems as part of [their] city services,‚Äù these systems must be cataloged in the city‚Äôs algorithm registry. [Amsterdam‚Äôs registry](https://algoritmeregister.amsterdam.nl/en/ai-register/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) currently has three entries: (1) license plate-recognizing [automated parking control](https://algoritmeregister.amsterdam.nl/automated-parking-control?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) cars, (2) a pilot for algorithm-assisted [fraud surveillance for holiday home rentals](https://algoritmeregister.amsterdam.nl/holiday-rental-housing-fraud-risk?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), and (3) a natural language processing system for [categorizing reports of trash in public space](https://algoritmeregister.amsterdam.nl/en/reporting-issues-in-public-space/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). These registries may become a good source of productized AI links for me, but more importantly, this is a great step for building transparency, trust and accountability into these systems.

## Machine Learning Research üéõ

* üñº [An Image is Worth 16x16 words: Transformers for Image Recognition at Scale](https://openreview.net/forum?id=YicbFdNTTy&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is a paper under review for ICLR 2020 that‚Äôs been [making the rounds on Twitter](https://twitter.com/karpathy/status/1312279279741276161?s=12&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). I found [Yannick Kilcher‚Äôs explainer video](https://youtu.be/TrdevFK_am4?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) ‚Äî which starts with a lovely rant about ‚Äúdouble-blind‚Äù peer review ‚Äî a good introduction to the model, which could be the start of Transformers overtaking convolutional models at the very largest scales of computer vision models.
* üë©üèæ‚Äçüíª Building on their previous three years of graduate school application mentoring programs, [Black in AI](https://blackinai.github.io?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) has launched an [Academic Positions program](https://blackinai.github.io/post/academic_programs/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) to support Black junior researchers getting started in ‚Äúcareers in academia, industry, and policy.‚Äù The [launch blog post](https://blackinai.github.io/post/academic_programs/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) includes details about the program, tips on how academics and organizations can support it, and lots of additional resources. This is a great link to amplify within your ML network!
* ‚ö°Ô∏è[TensorSensor](https://github.com/parrt/tensor-sensor?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is a Python package that ‚Äúclarifies‚Äù (visualizes) the dimensions of tensors in numpy, TensorFlow or PyTorch. I recently had to reproduce a paper that wrote down its math in a simplified form that ignored the out-channel dimension of convolutional filters, and spent a lot of time trying to get all my matrices to line up correctly with that extra dimension. This tool would‚Äôve made that a lot easier! Also check out [Terence Parr‚Äôs introduction to TensorSensor](https://explained.ai/tensor-sensor/index.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
* üîó Cool new [arXiv.org](https://arxiv.org?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) feature: [Papers with Code](https://paperswithcode.com?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)-discovered implementations [are now linked right on a paper‚Äôs abstract page](https://twitter.com/paperswithcode/status/1314214449083895808?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). I‚Äôve always found it quite easy to find any available implementations with a few quick Google and GitHub searches, but integrations like this are great for discoverability.

## Artificial Intelligence for the Climate Crisis üåç

* ‚õÖÔ∏è Some recent progress on nowcasting (predicting over the next few hours) the locations of clouds: [Berthomier et al. (2020)](https://arxiv.org/abs/2009.11577?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) compared the effectiveness of several deep learning models for the task, and Jack Kelly of [Open Climate Fix](https://openclimatefix.org/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) open-sourced [a Python notebook](https://github.com/openclimatefix/predict_pv_yield_2/blob/master/notebooks/optical_flow_1.ipynb?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) that approaches the same problem using optimal flow. This work is a step towards improving predictions of solar panels‚Äô power output, an important task for operators as an increasing fraction of the electricity supply on their grids transitions to solar.

## Cool Things ‚ú®

* üõ¥ I came across this short story by Janelle Shane when it premiered as a New York Times ‚ÄúOp-Ed From the Future‚Äù last year, but forgot to share it at the time. I rediscovered and reread it this week, and I still think it‚Äôs delightful: [We Shouldn‚Äôt Bother the Feral Scooters of Central Park](https://www.nytimes.com/2019/11/04/opinion/future-scooters-central-park.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
* üé® [Imaginaire](http://imaginaire.cc?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is NVIDIA‚Äôs universal library for image and video synthesis, including algorithms such as SPADE (GauGAN), pix2pixHD, MUNIT, FUNIT, COCO-FUNIT, vid2vid, few-shot vid2vid. Check out [this demo video](https://youtu.be/jgTX5OnAsYQ?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) to see what it‚Äôs capable of, from summer-to-winter transformations to automatically animating motion into pictures.

**Thanks for reading!**
As usual, you can let me know what you thought of today‚Äôs issue using the buttons below or by replying to this email.
If you‚Äôre new here, check out the [Dynamically Typed archives](https://dynamicallytyped.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or subscribe below to get a new issues in your inbox every second Sunday.

**If you enjoyed this issue of Dynamically Typed, why not forward it to a friend?**
It‚Äôs by far the best thing you can do to help me grow this newsletter.
üßÄ