---
category: productized-ai
data: 2020-06-21
issue_number: 42
title: Is it enough for only big tech to pull out of facial recognition?
---

**Big tech companies are putting an end to their facial recognition APIs.**
Beside their obvious privacy problems, commercial face recognition APIs have long been criticized for their inconsistent recognition accuracies for people of different backgrounds.
Frankly said, these APIs are better at identifying light-skinned faces than dark-skinned ones.
Joy Buolamwini and Timnit Gebru first documented a form of this in their 2018 [Gender Shades](http://gendershades.org/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) paper, and there have been many calls to block facial recognition APIs from being offered ever since; see [Jay Peter’s article in The Verge](https://www.theverge.com/2020/6/8/21284683/ibm-no-longer-general-purpose-facial-recognition-analysis-software?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) for some more historical context.

It took two years and the recent reckoning of discrimination and police violence in the United States (see [DT #41](https://dynamicallytyped.com/issues/41-black-lives-matter-highlighting-ml-ai-products-research-and-climate-projects-by-black-creators-251381?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)), for IBM to finally write [a letter to the US congress](https://www.ibm.com/blogs/policy/facial-recognition-susset-racial-justice-reforms/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) announcing they’re done with the technology:

> IBM no longer offers general purpose IBM facial recognition or analysis software.
> IBM firmly opposes and will not condone uses of any technology, including facial recognition technology offered by other vendors, for mass surveillance, racial profiling, violations of basic human rights and freedoms, or any purpose which is not consistent with our values and Principles of Trust and Transparency.

Amazon and Microsoft followed soon after, pausing police use of their equivalent APIs.
Notably Google, where Gebru works, has [never had a facial recognition API](https://twitter.com/jeffdean/status/1270961033616617473?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
Now that these big-name tech companies are no longer providing facial-recognition-as-a-service, however, this does expose a new risk.
Benedict Evans, in [his latest newsletter](https://mailchi.mp/bad1c520af3b/benedicts-newsletter-no-451186?e=2ce07ab429&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter):

> The catch is that this tech is now mostly a commodity (and very widely deployed in China) - Google can say “wait”, but a third-tier bucketshop outsourcer can bolt something together from parts it half-understands and sell it to a police department that says ‘it’s AI - it can’t be wrong!’.

This is a real risk, and that’s why the second half of these announcements is equally—if not more—important.
Also from IBM’s letter to congress:

> We believe now is the time to begin a national dialogue on whether and how facial recognition technology should be employed by domestic law enforcement agencies.

The real solution here is not for individual big tech companies to be publicly shamed into stopping their facial recognition APIs, but for the technology to be regulated by law—so that a “third-tier bucketshop outsourcer” can’t do the same thing, but out of the public eye.
So: these are good steps, but this week’s news is far from the last chapter in the story of face recognition.