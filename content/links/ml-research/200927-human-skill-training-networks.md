---
category: ml-research
date: 2020-09-27
emoji: "ğŸ‘©â€ğŸ”¬"
issue_number: 49
title: Human skill in training deep networks
---

Weâ€™ve seen â€œtuning hyperparameters without grad studentsâ€ with [Dragonfly](https://github.com/dragonfly/dragonfly?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) ([DT #11](https://dynamicallytyped.com/issues/11-adobe-and-google-s-new-video-ai-tools-stanford-s-hype-for-gans-and-a-conversation-with-books-170283?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) butâ€¦ how much does a researcherâ€™s experience actually correlate with their skills for tuning an ML model?
[Anand et al, (2020)](https://arxiv.org/abs/2008.05981?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) investigated this and found a strong positive correlation between experience and final model accuracy, and â€œthat an experienced participant finds better solutions using fewer resources on average.â€ Glad to see my skills arenâ€™t yet completely automatable yet!
(The paper is co-authored by [Jan van Gemert](https://jvgemert.github.io?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), who was the first person to explain to me what a convolution is, in a guest lecture during my first year of undergrad.
ğŸ˜Š)