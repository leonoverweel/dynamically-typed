---
category: productized-ai
date: 2020-08-02
emoji: "\U0001F9B8"
issue_number: 45
title: Fawkes image cloaking
---

‍Related: [Fawkes](http://sandlab.cs.uchicago.edu/fawkes/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is a new algorithm by Shan et al.
that makes imperceptible changes to portrait photos to fool facial recognition: “ _cloaked_ images will teach the model a highly distorted version of what makes you look like you.” The University of Chicago researchers wrapped Fawkes into a Windows and macOS app, and they claim that it’s 100% effective against the state-of-the-art models powering commercially available facial recognition APIs.
As my friends who study computer security tell me, though, this is always a cat-and-mouse game: at some point, someone will figure out how to make a facial recognition model that’s robust against Fawkes; and then someone else will make a Fawkes 2.0 that’s robust against _that;_ and then…
But, at least for a while, running your photos through Fawkes should make them unrecognizable to most facial recognition models out there.
Probably.