---
title: "#55: DeepMind&#x27;s structural biology breakthrough with AlphaFold 2 "
date: 2020-12-20
number: 55
aliases:
  - /issues/55-deepmind-s-structural-biology-breakthrough-with-alphafold-2-298998
---

Hey everyone, welcome to Dynamically Typed #55.
In today‚Äôs issue I‚Äôm mostly focusing on DeepMind‚Äôs new AlphaFold 2 (AF2) model, which I waited to dive into until last month‚Äôs hype settled down a bit; that story is right below this, in the ML research section.
It took pretty long to understand and boil down everything around AF2, so I‚Äôve only got a few other quick links in the other sections.

This is also the last DT of 2020 ‚Äî happy holidays everyone!
üéÑ

## Machine Learning Research üéõ

![AlphaFold's predictions vs. the experimentally-determined shapes of two CASP14 proteins.](https://s3.amazonaws.com/revue/items/images/006/966/376/mail/Screen_Shot_2020-12-19_at_17.17.34.png?1608396735)

_AlphaFold's predictions vs. the experimentally-determined shapes of two CASP14 proteins._

**ÔªøDeepMind‚Äôs AlphaFold 2 is a major protein folding breakthrough.**
Protein folding is a problem in structural biology where, given the one-dimensional RNA sequence of a protein, a computational model has to predict what three-dimensional structure the protein ‚Äúfolds‚Äù itself into.
This structure is much more difficult to determine experimentally than the RNA sequence, but it‚Äôs essential for understanding how the protein interacts with other machinery inside cells.
In turn, this can give insights into the inner workings of diseases ‚Äî ‚Äúincluding cancer, dementia and even infectious diseases such as COVID-19‚Äù ‚Äî and how to fight them.

Biennially since 1994, the Critical Assessment of Techniques for Protein Structure Prediction (CASP) has determined the state of the art in computational models for protein folding using a blind test.
Research groups are presented (only) with the RNA sequences of about 100 proteins whose shapes have recently been experimentally determined.
They blindly predict these shapes using their computational models and submit them to CASP to be evaluated with a Global Distance Test (GDT) score, which roughly corresponds to how far each bit of the protein is from where it‚Äôs supposed to be.
GDT scores range from 0 to 100, and a model that scores at least 90 across different proteins would be considered good enough to be useful to science (‚Äúcompetitive with results obtained from experimental methods‚Äù).

Before CASP13 in 2018, no model had ever scored significantly above 40 GDT.
That year, the first version of AlphaFold came in at nearly 60 GDT ‚Äî already ‚Äústunning‚Äù at the time (see [DT #21](https://dynamicallytyped.com/issues/21-deepmind-s-ml-for-drug-discovery-security-leaks-in-neural-networks-and-green-ai-194986?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)).
At CASP14 this year, AlphaFold 2 blew its previous results out of the water and achieved a median score of _92.4 GDT across all targets._ This was high enough for CASP to [declare the problem as ‚Äúsolved‚Äù in their press release](https://predictioncenter.org/casp14/doc/CASP14_press_release.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and to start talking about new challenges for determining the shape of multi-protein complexes.

I‚Äôve waited a bit to write about AlphaFold 2 until the hype died down because, oh boy, was there a lot of hype.
DeepMind released [a slick video about the team‚Äôs process](https://www.youtube.com/watch?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=gg7WjuFs8F4), their results were covered with glowing features in [Nature](https://www.nature.com/articles/d41586-020-03348-4?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and [The New York Times](https://www.nytimes.com/2020/11/30/technology/deepmind-ai-protein-folding.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), and high praise came even from the leaders of DeepMind‚Äôs biggest competitors, including OpenAI‚Äôs [Ilya Sutskever](https://twitter.com/ilyasut/status/1333445199603744768?s=12&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and Stanford HAI‚Äôs [Fei-Fei Li](https://twitter.com/drfeifei/status/1333587506055372800?s=20&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
It was a pretty exciting few days on ML twitter.

Columbia University‚Äôs Mohammed AlQuraishi, who has been [working on protein folding](https://www.aqlab.io/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) for over a decade, was one of the first people to [break the CASP14 news](https://twitter.com/MoAlQuraishi/status/1333383634649313280?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
His [blog post about CASP13 and AlphaFold 1](https://moalquraishi.wordpress.com/2018/12/09/alphafold-casp13-what-just-happened/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) was also widely circulated back in 2018, so a lot of people in the field were interested in what he‚Äôd have to say this year.
Last week, after the hype died down a bit, AlQuraishi published [his perspective on AlphaFold 2](https://moalquraishi.wordpress.com/2020/12/08/alphafold2-casp14-it-feels-like-ones-child-has-left-home/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
He summarized it by saying ‚Äúit feels like one‚Äôs child has left home:‚Äù AF2 got results he did not expect to see until the end of this decade, even when takin into account AF1 ‚Äî bittersweet for someone whose lab has also been working on this same problem for a long time.

AlQuraishi is overall extremely positive about DeepMind‚Äôs results here, but he does express disappointment at their ‚Äúfalling short of the standards of academic communication‚Äù ‚Äî the lab has so far been much more secretive about AF2 than it was about AF1 (which is [open-source](https://github.com/deepmind/deepmind-research/tree/master/alphafold_casp13?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)).
AlQuraishi‚Äôs post is very long and technical, but if you want to know exactly how impressive AlphaFold 2 is, learn the basics of how it works, read about its potential applications in broader biology, or see some of the hot takes against it debunked, the post is definitely worth the ~75 minutes of your time.
(I always find it energizing to see someone excitedly explain a big advancement in their field that they did not directly work on; [here‚Äôs the link again](https://moalquraishi.wordpress.com/2020/12/08/alphafold2-casp14-it-feels-like-ones-child-has-left-home/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).)

I personally also can‚Äôt wait to see the first practical applications of AlphaFold, which I expect we‚Äôll start to see DeepMind talk about in the coming years.
(Hopefully!) For one, they‚Äôve already released [AlphaFold‚Äôs predictions for some proteins associated with COVID-19](https://deepmind.com/research/open-source/computational-predictions-of-protein-structures-associated-with-COVID-19?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

**Quick ML research + resource links** üéõ

* üì∞ There are some new developments in Google‚Äôs ongoing AI ethics crisis (see [DT #54](https://dynamicallytyped.com/issues/54-google-ai-s-ethics-crisis-an-adversarial-attack-on-deepfake-detectors-and-stanford-s-ognet-climate-project-295371?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)). CEO Sundar Pichai issued [a company-wide memo](https://www.axios.com/sundar-pichai-memo-timnit-gebru-exit-18b0efb0-5bc3-41e6-ac28-2956732ed78b.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) apologizing for the fact that ‚ÄúDr. [Timnit] Gebru‚Äôs departure ‚Ä¶ seeded doubts and led some in our community to question their place at Google.‚Äù This doesn‚Äôt address the central issue, and it did not land well with the community; see the tweets from [Gebru](https://twitter.com/timnitGebru/status/1336777379730116615?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and [Jack Clark](https://twitter.com/jackclarkSF/status/1336776902099390464?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), as well as [Khari Johnson‚Äôs interview with Gebru](https://venturebeat.com/2020/12/10/timnit-gebru-googles-dehumanizing-memo-paints-me-as-an-angry-black-woman/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and [NPR‚Äôs coverage of the story](https://www.npr.org/2020/12/17/947719354/ousted-black-google-researcher-they-wanted-to-have-my-presence-but-not-me-exactl?t=1608388688095&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). In response to the memo, a group of Google AI researchers sent the executives [a list of demands](https://www.bloomberg.com/news/articles/2020-12-16/google-ai-researchers-lay-out-demands-escalating-internal-fight?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) asking for leadership and policy changes. And meanwhile, someone made [a fake Twitter account](https://twitter.com/mantzarlis/status/1337784486826831876?s=12&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) (complete with a GAN-generated profile picture) that opposed Gebru‚Äôs side of the story by pretending to be an ex-researcher from the Google ethics team. I don‚Äôt think this‚Äôll be resolved anytime soon.
* ‚ú≥Ô∏è Chris Olah et al. have a cool new Distill article in the [Circuits thread](https://distill.pub/2020/circuits/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter): [Naturally Occurring Equivariance in Neural Networks](https://distill.pub/2020/circuits/equivariance/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). ‚ÄúWe sometimes think of understanding neural nets as being like reverse engineering a regular computer program. In this analogy, equivariance is like finding the same inlined function repeated throughout the code.‚Äù
* ‚ö°Ô∏èThe SE4ML lab‚Äôs updated [Engineering best practices for Machine Learning](https://se-ml.github.io/practices/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) includes tips for managing data, code, training, deployment, teams, and high-level governance.

_I‚Äôve also collected all 75+ ML research tools previously featured in Dynamically Typed_[ _on a Notion page_](https://www.notion.so/adab36fecaea4306880898f41dcb9cb3?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=cb3a74562c914234ac171931dad6c2e4) _for quick reference.
‚ö°Ô∏è_

## Artificial Intelligence for the Climate Crisis üåç

* üåç [Climate Change AI](https://www.climatechange.ai/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)‚Äôs NeurIPS 2020 Workshop on [Tackling Climate Change with Machine Learning](https://www.climatechange.ai/events/neurips2020?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) happened last week, featuring nearly 100 papers and proposals. I haven‚Äôt had the time to properly read through everything yet, but it looks like there‚Äôs a lot of great work to dive into over the holidays!

## Cool Things ‚ú®

* üé® Also from NeurIPS 2020: the gallery for this year‚Äôs workshop on [Machine Learning for Creativity and Design](https://neurips2020creativity.github.io?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is live! I really enjoyed looking through all the new work in the online gallery, which is available at [aiartonline.com](http://www.aiartonline.com?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
* üéæ Technology-driven design studio [Bakken & B√¶ck](https://bakkenbaeck.com?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) wrote [a blog post](https://medium.com/bakken-b%C3%A6ck/improving-your-tennis-game-with-computer-vision-863969743024?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) about a recent computer vision project they did that lets tennis players compare their own swing with the pros, to ‚Äúswing like Serena.‚Äù The article explains how their model works and includes some nice visuals.

**Thanks for reading!**
As usual, you can let me know what you thought of today‚Äôs issue using the buttons below or by replying to this email.
If you‚Äôre new here, check out the [Dynamically Typed archives](https://dynamicallytyped.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or subscribe below to get a new issues in your inbox every second Sunday.

**If you enjoyed this issue of Dynamically Typed, why not forward it to a friend?**
It‚Äôs by far the best thing you can do to help me grow this newsletter.
üéÖ