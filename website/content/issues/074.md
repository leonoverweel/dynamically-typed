---
title: "#74: Apple&#x27;s privacy-focused facial recognition, DeepMind&#x27;s multimodal Perceiver IO, and sea ice forecasting with IceNet "
date: 2021-09-12
number: 74
aliases:
  - /issues/74-apple-s-privacy-focused-facial-recognition-deepmind-s-multimodal-perceiver-io-and-sea-ice-forecasting-with-icenet-741830
---

Hey everyone, welcome to Dynamically Typed #74!
Today‚Äôs productized AI section includes some updates on the ClipDrop app and a detailed Apple blog post about privacy-preserving facial recognition in the Photos app.
I also covered DeepMind‚Äôs new general Perceiver IO architecture for ML research, and IceNet for climate AI.
And finally, for cool stuff I found Omnimatte, which we‚Äôll probably see integrated into most video editing software a few years from now.
Happy reading!

_(This issue is a bit later than usual because preseason just started at rowing and the first few practices have been exhausting (but very fun).
Anyway, I‚Äôve finally figured out how to upload GIFs in DT so I hope those make up for the tardiness.)_

## Productized Artificial Intelligence üîå

![ClipDrop demo. (ClipDrop)](https://s3.amazonaws.com/revue/items/images/011/046/166/original/clipdrop.gif?1631449129)

_ClipDrop demo. (ClipDrop)_

* üì± I first covered Cyril Diagne‚Äôs [AR cut and paste](https://dynamicallytyped.com/links/cool-things/200510-ar-cut-and-paste/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) tool in May 2020 when it was a cool tech demo on Twitter, and then again when he [productized it as ClipDrop](http://ClipDrop%20) in October. As a reminder, ClipDrop lets you take a picture of an object which it then segments (‚Äúclips‚Äù) out of the background so that you can paste (‚Äúdrop‚Äù) it onto a canvas on your laptop in AR. Diagne has [kept busy](https://twitter.com/cyrildiagne/status/1435945635354759169?s=12&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) since the initial launch: he did Y Combinator, raised a seed round, and grew the team. ClipDrop now has 11,000 paying customers; it‚Äôs also launching a new web app and an API. (Register for access to the private beta [here](https://docs.google.com/forms/d/16ncPf4kga92_Q8hAJALTjq2cIzBIujeq7KT7XbhR6vc/edit?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).) It‚Äôs another great example of AI enabling creativity software ‚Äî see also [Photoshop‚Äôs Neural Filters](https://dynamicallytyped.com/stories/2020/photoshop-neural-filters/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [Rosebud AI‚Äôs GAN photo models](https://dynamicallytyped.com/stories/2020/rosebud-ai-gan-photo-model/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), all the [Spleeter-powered apps](https://dynamicallytyped.com/stories/2020/one-ai-model-four-competing-services/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), and of course [RunwayML](https://dynamicallytyped.com/links/productized-ai/201122-runwayml-green-screen/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and [Descript](https://dynamicallytyped.com/links/productized-ai/201025-descript-for-video/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
* üïµÔ∏è‚Äç‚ôÄÔ∏è Apple‚Äôs machine learning blog has a detailed new post about their privacy-focused, on-device implementation of [facial recognition in the Photos app](https://machinelearning.apple.com/research/recognizing-people-photos?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). Some interesting details, in no particular order: (1) people are identified not only by embeddings of their face, but also by their upper body and metadata from the photo ‚Äî two photos taken a few minutes apart are relatively likely to contain the same person; (2) an iterative clustering algorithm first groups very certain matches, then groups those groups, etc, and once it‚Äôs no longer certain it asks the user whether two clusters are still the same person; (3) constant re-evaluations of bias in the training dataset serve as a guide to what gaps to fill in new rounds of data collection; (4) running on a recent Apple Neural Engine, face embedding generation takes only 4 milliseconds. I‚Äôve recently switched from Google Photos to Apple Photos, and one thing about their person recognition is definitely impressive: Google thinks two of my friends who are twins are the same person, and Apple can keep them apart.

_More productized AI:_[ _stories_](https://dynamicallytyped.com/stories/productized-ai?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) _(22),_[ _links_](https://dynamicallytyped.com/links/productized-ai?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) _(73)_

## Machine Learning Research üéõ

* üîé [Perceiver IO](https://deepmind.com/blog/article/building-architectures-that-can-handle-the-worlds-data?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is DeepMind‚Äôs new general-purpose architecture for processing a wide variety of input modalities ‚Äî like images, videos, 3D point clouds, and sounds ‚Äî into output vectors. First, [Perceiver](https://arxiv.org/abs/2103.03206?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) (without the IO) scaled Transformers‚Äô concept of attention to much larger input sizes, ‚Äúwithout introducing domain-specific assumptions,‚Äù by first encoding the inputs to a small fixed-size latent array and attending over that. Now, Perceiver IO ([arXiv](https://arxiv.org/abs/2107.14795?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [GitHub](https://github.com/deepmind/deepmind-research/tree/master/perceiver?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) extends this by also applying attention to the decoding side, so that one input can produce multiple outputs and both the inputs and outputs can be a mix of modalities. ‚ÄúThis opens the door for all sorts of applications, like understanding the meaning of a text from each of its characters, tracking the movement of all points in an image, processing the sound, images, and labels that make up a video, and even playing games, all while using a single architecture that‚Äôs simpler than the alternatives.‚Äù With OpenAI releasing [DALL¬∑E and CLIP](https://dynamicallytyped.com/stories/2021/openai-dall-e-clip/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and Stanford HAI launching [the Foundation Models research center](https://crfm.stanford.edu?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), both also this year, these large multimodal networks have become a central focus of leading AI labs.

_More ML research:_[ _stories_](https://dynamicallytyped.com/stories/ml-research?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) _(14),_[ _links_](https://dynamicallytyped.com/links/ml-research?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) _(82)_

## Artificial Intelligence for the Climate Crisis üåç

* üßä [IceNet](https://www.nature.com/articles/s41467-021-25257-4?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is a new probabilistic, deep learning sea ice forecasting system ‚Äútrained on climate simulations and observational data to forecast the next 6 months of monthly-averaged sea ice concentration maps.‚Äù It‚Äôs a U-Net model that uses 50 climate variables as input, and outputs discrete probability distributions for three different sea ice concentration classes at each grid cell. Coolest (haha) part: ‚ÄúIceNet runs over 2000 times faster on a laptop than SEAS5 running on a supercomputer, taking less than ten seconds on a single graphics processing unit.‚Äù Practical use cases are in planning shipping routes and in avoiding conflicts between ships and migrating walruses and whales. Pretty cool.

_More climate AI:_[ _stories_](https://dynamicallytyped.com/stories/climate-ai?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) _(6),_[ _links_](https://dynamicallytyped.com/links/climate-ai?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) _(33)_

## Cool Things ‚ú®

![Omnimatte masks both objects (the car) and their effects (the dust), enabling adding the ML DRIFT logo "behind" the dust. (Lu et al. 2021)](https://s3.amazonaws.com/revue/items/images/011/050/868/original/ezgif.com-gif-maker.gif?1631468628)

_Omnimatte masks both objects (the car) and their effects (the dust), enabling adding the ML DRIFT logo "behind" the dust. (Lu et al. 2021)_

* üí® [Omnimatte](https://ai.googleblog.com/2021/08/introducing-omnimattes-new-approach-to.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is a new matte/mask generation model by Erika Lu, who developed it in collaboration with Google AI researchers during two internships there. Unlike other state-of-the-art segmentation networks, Omnimatte creates masks for both objects and their ‚Äúeffects‚Äù like shadows or dust clouds in videos, enabling editors to easily add layers of content between the background and a foreground subject in a realistic way. Forrester Cole and Tali Dekel explain how the model works in detail (with lots of gifs!) in [a post on the Google AI Blog](https://ai.googleblog.com/2021/08/introducing-omnimattes-new-approach-to.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

_More cool things:_[ _stories_](https://dynamicallytyped.com/stories/cool-things?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) _(5),_[ _links_](https://dynamicallytyped.com/links/cool-things?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) _(26)_

**Thanks for reading!**
As usual, you can let me know what you thought of today‚Äôs issue using the buttons below or by replying to this email.
If you‚Äôre new here, check out the [Dynamically Typed archives](https://dynamicallytyped.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or subscribe below to get a new issues in your inbox every second Sunday.

**If you enjoyed this issue of Dynamically Typed, why not forward it to a friend?**
It‚Äôs by far the best thing you can do to help me grow this newsletter.
üö£‚Äç‚ôÇÔ∏è