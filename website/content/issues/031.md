---
title: "#31: Uber&#x27;s Generative Teaching Networks, ML Super Resolution in Pixelmator Pro, and Evolve Energy "
date: 2020-01-19
number: 31
aliases:
  - /issues/31-uber-s-generative-teaching-networks-ml-super-resolution-in-pixelmator-pro-and-evolve-energy-219307
---

Hey everyone, welcome to Dynamically Typed #31!
Today‚Äôs issue is back to the familiar format, with some productized AI‚Äîa new machine learning-powered image upscaling feature in the Pixelmator Pro photo editing app‚Äîand some ML research‚ÄîUber‚Äôs Generative Teaching Networks for faster neural architecture searches.
For climate change AI, I‚Äôm covering a Texas-based startup called Evolve Energy that uses machine learning to predict the carbon intensity of the electricity grid over time and adjust its users‚Äô energy use accordingly.

Finally, I‚Äôm also trying something new: in each section, I‚Äôm including a few more cool links that came across my radar, but that I‚Äôm not covering in detail.
There are quite a few of those in today‚Äôs DT, since my mom is visiting me in the Netherlands, and we‚Äôre painting my apartment this weekend!
Three of my living room walls are now a gorgeous ‚Äúficus‚Äù dark green.
üçÉ

## Productized Artificial Intelligence üîå

![Traditional Lanczos image scaling (left) vs. Pixelmator's ML Super Resolution (right).](https://s3.amazonaws.com/revue/items/images/005/438/009/mail/7aa6c012560888ef571ba22e4426a2e0.png?1579244221)

_Traditional Lanczos image scaling (left) vs. Pixelmator's ML Super Resolution (right)._

**Photo editing app Pixelmator Pro has added a machine learning-powered image resizing function.**
There are lots of traditional algorithms for increasing the resolution of an image.
For a 2x increase, like going from a 500 x 300 pixel image to 1,o00 x 600 px, for example: _nearest neighbor_ interpolation simply makes four copies of each pixel; _bilinear_ interpolation fills new pixels with the average color of its four neighboring pixels; and _Lanczos_ interpolation is a bit [more complex](https://en.wikipedia.org/wiki/Lanczos_resampling?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter#Interpolation_formula).
What these traditional algorithms have in common is that they‚Äôre static, not learned: people thought long and hard about them, and then wrote them down as formulae.

But in recent years, much like in other computer vision tasks like image classification and object detection, machine learning has started competing with these traditional algorithms.
In a supervised task called _superresolution_ , a convolutional neural network model is trained on pairs of low-resolution and high-resolution images‚Äîa dataset that can be generated quite easily by taking HD photos and down-scaling them.
From this data, the model can learn to generate high-resolution images from low-resolution inputs.
For more technical details, see this survey by [Wang, Chen and Hoi (2019)](https://arxiv.org/abs/1902.06068?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

Pixelmator Pro has now added such a model to its app, in an easy-to-use way that requires no AI knowledge to use: _ML Super Resolution_ is simply another button to click in the app, making this a great example of productized AI.
Pixelmator wrote a very good blog post announcing the feature‚Äîincluding details like their network design and use of Apple‚Äôs Core ML 3 framework to speed up computation!‚Äîwhich you can read here: [All about the new ML Super Resolution feature in Pixelmator Pro](https://www.pixelmator.com/blog/2019/12/17/all-about-the-new-ml-super-resolution-feature-in-pixelmator-pro/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

**Quick productized AI links üîå**

* üì± Follow-up: Itay Inbar and Nir Shemy for the Google AI Blog: [The On-Device Machine Learning Behind Recorder](https://ai.googleblog.com/2019/12/the-on-device-machine-learning-behind.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), covering the tech behind the on-device transcription feature I covered in [DT #25](https://dynamicallytyped.com/issues/25-ai-powered-rainforest-monitoring-google-s-pixel-4-and-openai-s-rubik-s-cube-solving-robot-hand-204685?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

## Machine Learning Research üéõ

![An overview of generative teaching networks (GTNs).](https://s3.amazonaws.com/revue/items/images/005/441/290/mail/b3d1ff5176d0e1de9820bfc2110de397.jpeg?1579282063)

_An overview of generative teaching networks (GTNs)._

**Such et al.
at Uber AI labs introduced Generative Teaching Networks (GTNs),** a method to generate synthetic training data to speed up neural architecture search (NAS) algorithms.
A NAS is a way to explore a design space of potential neural network architectures with different layer counts, depths, connections, etc.
to find an architecture that performs well on a given task and set of design constraints.
A NAS may explore a space of many thousands of possible networks, and each network needs to be trained (to some extent) to evaluate its performance on the task at hand.
So neural architecture searches are usually computationally very expensive to perform, and have historically mostly been done by well-funded corporate AI labs; see MobileNetV3 by [Howard et al.
(2019)](https://arxiv.org/abs/1905.02244?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) at Google AI and FBNet by [Wu et al.
(2019)](http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_FBNet_Hardware-Aware_Efficient_ConvNet_Design_via_Differentiable_Neural_Architecture_Search_CVPR_2019_paper.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) at Facebook AI Research for example.

Here‚Äôs how it works, following the diagram above:

> A GTN is like the generator in a generative adversarial network (GAN), except without a pressure to make data look realistic.
> Instead, it produces completely artificial data that a never-seen-before learner neural network (with a randomly sampled architecture and weight initialization) trains on for a small number of learning steps, e.g., the steps could be via stochastic gradient descent (SGD).
> Afterwards, the learner network‚Äìwhich so far has never seen real data‚Äìis evaluated on real data (e.g., whether it can recognize handwritten images in the classic MNIST dataset), which provides the meta-loss objective that is being optimized.
> We then differentiate _through the entire learning process_ via meta-gradients to update the GTN parameters to improve performance on the target task.
> The learner is then discarded and the process repeats.

By training for fewer steps on synthetic GTN-generated data, Such et al.‚Äôs NAS sped up 9x!
‚ÄúGTN-generated data is thus a faster drop-in replacement for real data in NAS algorithms.‚Äù This is very cool, and GTN-generated datasets may open neural architecture searches up to more research teams.
Read more on the [Uber engineering blog](https://eng.uber.com/generative-teaching-networks/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or in the paper by [Such et al.
(2019)](https://arxiv.org/abs/1912.07768?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

Related, also check out this Toward Data Science post by Jesus Rodriguez: [Uber Has Been Quietly Assembling One of the Most Impressive Open Source Deep Learning Stacks in the Market](https://towardsdatascience.com/uber-has-been-quietly-assembling-one-of-the-most-impressive-open-source-deep-learning-stacks-in-b645656ddddb?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
I‚Äôve covered some tools of the tools Rodriguez mentions here in the newsletter, like Michelangelo ([DT #5](https://dynamicallytyped.com/issues/5-hey-google-what-s-a-golden-kitty-153366?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) and Ludwig ([DT #7](https://dynamicallytyped.com/issues/7-no-code-no-problem-from-indie-makers-to-machine-learning-158462?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)).

**Quick ML research links** üéõ

* üë®‚Äçüî¨ Jeff Dean wrote a detailed post about Google‚Äôs past year of AI research and their future plans: [Google Research: Looking Back at 2019, and Forward to 2020 and Beyond](https://ai.googleblog.com/2020/01/google-research-looking-back-at-2019.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). Climate AI is mentioned less than I expected.
* üßÆ Cool new results form Charton and Lampe at Facebook AI research: [Using neural networks to solve advanced mathematics equations](https://ai.facebook.com/blog/using-neural-networks-to-solve-advanced-mathematics-equations/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). They tackle the problem using neural machine translation techniques, and even manage to solve some equations that advanced specialized software like Mathematica and Matlab can‚Äôt solve. (Thanks [Casper](https://twitter.com/CasperBoone?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)!)
* üëÅ Jeremy Howard‚Äôs fast.ai introduction to self-supervised learning for vision: [Self-supervised learning and computer vision](https://www.fast.ai/2020/01/13/self_supervised/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)
* üê¶ New Distill publication by Strumfels, Lundberg and Lee: [Visualizing the Impact of Feature Attribution Baselines](https://distill.pub/2020/attribution-baselines/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)

**Quick ML resource links ‚ö°Ô∏è** ([see all 50](https://www.notion.so/adab36fecaea4306880898f41dcb9cb3?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=cb3a74562c914234ac171931dad6c2e4))

* Jeremy Howard‚Äôs (fast.ai) [data project checklist](https://www.fast.ai/2020/01/07/data-questionnaire/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), covering strategy, data, analytics, implementation, maintenance, and constraints considerations.

## Artificial Intelligence for the Climate Crisis üåç

**Evolve Energy uses machine learning to predict the carbon intensity of the energy grid.**
Through its app, it then automatically adjusts its users‚Äô energy use to be higher during cheaper and lower-impact times.
For example, when Evolve predicts a windy, sunny morning but a cloudy, calm afternoon, it makes sure you charge your electric car in the morning when there‚Äôs lots of solar and wind energy available.
[Seth Colaner for VentureBeat](https://venturebeat.com/2019/11/05/evolve-energy-uses-machine-learning-and-analytics-to-save-renewable-energy-customers-money/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter):

> The technology includes pulling in real-time data, like how and when customers are using electricity, ambient temperatures, time of day, duration, patterns in preferences and behaviors, and so on.
> ‚Ä¶ Based on that data, Evolve Energy runs a recommendation engine that tells customers what it‚Äôs going to do for them.
> Customers can override the recommendations if they choose, and the app will instantly inform them what the resultant costs will be.
> It‚Äôs a balance, Lee said, involving transparency, control, and feedback.

Evolve can do all this because, instead of selling customers power at a flat rate like other power companies do, it resells power at wholesale prices, in 5-minute increments without charging a markup.
Instead, it makes money by charging a $10/month fee for its app and predictive technology.
CEO Michael Lee: ‚ÄúAnd by doing that, we are now aligning our interests for our customers to no longer sell them ‚Ä¶ electricity, but to become an advisor to our customers.‚Äù I love this alignment of incentives, and it‚Äôll be exciting to see products like Evolve spread to other regions.
(They‚Äôre currently only in Texas.) Check out [Evolve Energy‚Äôs website](https://www.evolvemyenergy.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) for more details about [how it works](https://www.evolvemyenergy.com/how-it-works?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and [how it helps decrease carbon emissions](https://www.evolvemyenergy.com/carbon-savings?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).

(Related: [WattTime](https://www.watttime.org/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is a nonprofit alternative, though it‚Äôs slightly less consumer-facing.)

**Quick climate AI links** üåç

* üåß Jason Hicket for the Google AI Blog: [Using Machine Learning to ‚ÄúNowcast‚Äù Precipitation in High Resolution](https://ai.googleblog.com/2020/01/using-machine-learning-to-nowcast.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)
* üõ¢ David on the Climate Change AI forum: [Artificial Intelligence and the Fossil Fuel Industry](https://forum.climatechange.ai/t/artificial-intelligence-and-the-fossil-fuel-industry/1031?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), covering the Vox video that recently made the rounds recently ([Google and Amazon are now in the oil business](https://forum.climatechange.ai/t/artificial-intelligence-and-the-fossil-fuel-industry/1031?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) and more.

**Thanks for reading!**
As usual, you can let me know what you thought of today‚Äôs issue using the buttons below or by replying to this email.
If you‚Äôre new here, check out the [Dynamically Typed archives](https://dynamicallytyped.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or subscribe below to get a new issues in your inbox every second Sunday.

**If you enjoyed this issue of Dynamically Typed, why not forward it to a friend?**
It‚Äôs by far the best thing you can do to help me grow this newsletter.
ü§ü