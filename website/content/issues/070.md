---
title: "#70: Karpathy on Tesla Autopilot at CVPR&#x27;21, Distill&#x27;s hiatus, and tattling on Flemish Scrollers using computer vision "
date: 2021-07-18
number: 70
aliases:
  - /issues/70-karpathy-on-tesla-autopilot-at-cvpr-21-distill-s-hiatus-and-tattling-on-flemish-scrollers-using-computer-vision-679755
---

Hey everyone, welcome to Dynamically Typed #70.
For today‚Äôs edition I summarized Andrej Karpathy‚Äôs talk about updates to Tesla‚Äôs Autopilot system at CVPR ‚Äò21.
Further in the productized AI section, I have links for a LEGO-detection app and the automated chip design methodology used to design Google‚Äôs latest generation of TPUs.
For ML research, I wrote about Distill‚Äôs one-year hiatus and the open-sourcing of DeepMind‚Äôs AlphaFold model.
Finally, for climate change AI I covered the launch of the CCAI Wiki, and for cool things I found a project that tattles on Flemish politicians for looking at their phone during debates.
Happy Sunday!

## Productized Artificial Intelligence üîå

**Karpathy on Tesla Autopilot at CVPR ‚Äò21**

Tesla‚Äôs head of AI Andrej Karpathy did [a keynote at the CVPR 2021 Workshop on Autonomous Driving](https://www.youtube.com/watch?index=11&list=PLvXze1V52Yy2OY67mz2Jy-JcnEw8GUZEl&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=g6bOwQdCJrc) with updates on the company‚Äôs Autopilot self-driving system.
Just like [his talk last year at Scaled ML 2020](https://www.youtube.com/watch?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=hx7BXih7zx8), this was a great watch if you‚Äôre interested in productized AI.
The talk kicks off with the value that ‚Äúincremental autonomy‚Äù is already providing today, in the form of automatic emergency braking, traffic control warnings (‚Äúthere‚Äôs a red light ahead!‚Äù), and pedal misapplication mitigation (PMM) ‚Äî stopping the driver from flooring it when they meant to hit the brakes.

![Examples of "incremental autonomy"](https://s3.amazonaws.com/revue/items/images/010/145/781/mail/E4bgtv6WQAY_PWB.jpeg?1626531015)

_Examples of "incremental autonomy"_

Karpathy then goes into details of the next generation of Autopilot: Tesla has ‚Äúdeleted‚Äù the radar sensor from recent new cars and is now relying on vision alone.
‚ÄúIf our [human] neural network can determine depth and velocity, can synthetic neural nets do it too?
Internally [at Tesla], our answer is an unequivocal yes.‚Äù This is backed by the fact that the new vision-only approach for Autopilot has a higher precision _and_ recall than the previous sensor fusion approach.

Where does the Autopilot team get a large and diverse enough dataset to train a vision model like this?
From the million-car fleet of course!
There are now 221 manually-implemented triggers running on the Tesla fleet to detect scenarios that they may want to look at for training data.
(Could ‚Äúinactive traffic lights on the back of a moving truck‚Äù [be the 222nd](https://twitter.com/layon_overwhale/status/1400522140240252932?s=20&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)?) Once collected, these images are labeled offline with a combination of human annotators, the old radar sensors, and very large neural nets ‚Äî which would be too slow to deploy in the cars, but are very useful in this offline setting.

![](https://s3.amazonaws.com/revue/items/images/010/145/787/mail/E4bjxLUX0As78mS.jpeg?1626531089)

The loop of the Tesla Data Engine is then: (1) deploy models in ghost mode; (2) observe their predictions; (3) fine-tune triggers for collecting new training data; (4) create new unit tests out of wrong predictions; (5) add similar examples to the dataset; (6) retrain; and repeat.
At 1.5 petabytes, the final dataset for this first release of the new Autopilot system went through this shadow mode loop seven times.
It contains six billion labeled objects across one million 10-second videos.

![](https://s3.amazonaws.com/revue/items/images/010/145/846/mail/E4bmg_ZXwAEtWmr.jpeg?1626531654)

The neural network trained on this data has a ResNet-ish backbone for basic image processing, which branches into ‚Äúheads,‚Äù then ‚Äútrunks,‚Äù and then ‚Äúterminal‚Äù detectors.
This amortizes learning into different levels, and allows multiple engineers to first work on different heads in parallel and then sync up to retrain the backbone.
I hadn‚Äôt heard of this structure for letting a large (50-ish person) team collaborate on one big neural network before ‚Äî very cool.

![](https://s3.amazonaws.com/revue/items/images/010/145/851/mail/E4bnYSzWQAwU3_H.jpeg?1626531790)

And finally, on the deployment side, Tesla is now also vertically-integrated: they built their own FSD (‚ÄúFull Self Driving‚Äù) Computer, with their own neural engine.

Karpathy wrapped by re-emphasizing auto-labeling: using a much heavier model than you could ever use in production to do (a first stab at) data labeling offline, to then be cleaned up a bit by a human, is very powerful.
And his overall conclusion remained in line with Tesla‚Äôs overall stance on self-driving: no fleet, no go.

**Quick productized AI links üîå**

* üß± [Brickit](https://brickit.app?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is an [iOS app](https://apps.apple.com/nl/app/brickit-rebuild-your-lego/id1477221636?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) that uses computer vision to identify LEGO bricks in a big pile and then [shows you a list of projects you can build with those bricks](https://twitter.com/AlexanderNL/status/1410253599502962692?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) ‚Äî with instructions! The most impressive part is that it can detect so many small objects with so many different classes in one photo. I‚Äôd guess it does this by tiling the image or sliding a window over the photo, and then running the smaller images through some custom model powered by [Core ML](https://developer.apple.com/documentation/coreml?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and the iPhone‚Äôs neural engine; but I can‚Äôt find information much about how the app works exactly. Brickit is a great example of productized AI: its core functionality is enabled by a highly-complex machine learning, but it abstracts this away into a simple user interface.
* üñ• Google AI researchers Azalia Mirhoseini and Anna Goldie published a Nature paper on their [AI-powered computer chip design methodology,](https://www.nature.com/articles/s41586-021-03544-w?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) which uses ‚Äúan edge-based graph convolutional neural network architecture capable of learning rich and transferable representations of the chip.‚Äù Trained on a dataset of 10,000 chip floorplans, the method replaces ‚Äúmonths of intense effort‚Äù for humans, and comes up with a more optimal end result. [I covered this research](https://dynamicallytyped.com/links/ml-research/200426-chip-design-with-reinforcement-learning/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) when it first came out in April 2020, but the big news now is that it has been productionized: Mirhoseini and Goldie have used it to design the next generation of Google‚Äôs Tensor Processing Units (TPUs)!

## Machine Learning Research üéõ

* ‚è∏ Distill, [my](https://dynamicallytyped.com/stories/2020/distill-zoom-in-on-circuits/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) [favorite](https://dynamicallytyped.com/stories/2020/distill-early-vision-in-cnns/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) [machine](https://dynamicallytyped.com/stories/2020/distill-exploring-bayesian-optimization/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) [learning](https://dynamicallytyped.com/links/ml-research/210411-distill-multimodal-neurons/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) [journal](https://dynamicallytyped.com/links/ml-research/210411-distill-branch-specialization/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), is [going on hiatus](https://distill.pub/2021/distill-hiatus/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). Maybe I jinxed this last month when I hoped that [the founding of Anthropic](https://dynamicallytyped.com/links/ml-research/210606-anthropic-series-a/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), a new AI safety research company started by many of the people behind Distill, wouldn‚Äôt impact their work on the journal. Oops. Over the past five years, Distill‚Äôs innovations of being web-only ‚Äî not forcing articles to fit into two-column static PDFs ‚Äî and explicitly caring about publishing explainers and artifacts, have pushed AI explainability to a whole new level. I‚Äôll miss this feed of highly-polished interactive articles a lot, but I also understand the editorial team‚Äôs decision here: they found that their mentorship, article template, community, and dedicated authors were more central to the excellent quality of work on Distill, than the fact that Distill is its own journal was. They think the future of Distill-style articles is self-publication, ‚Äúeither on one-off websites or on a hypothetical ‚ÄòDistill Arxiv.‚Äô‚Äù See [the editorial team‚Äôs blog post](https://distill.pub/2021/distill-hiatus/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) for more of their thoughts on this, and some other considerations ‚Äî volunteer burnout also played a role.
* üß¨ AlphaFold, DeepMind‚Äôs protein folding neural network that [represented a breakthrough in structural biology](https://dynamicallytyped.com/stories/2020/deepmind-alphafold-2/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), is now open-source. The model‚Äôs paper, _Highly accurate protein structure prediction with AlphaFold_ by [Jumper et al. (2021)](https://www.nature.com/articles/s41586-021-03819-2?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), got published in Nature; the code is on GitHub at [deepmind/alphafold](https://github.com/deepmind/alphafold?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). Lots of people in the community were asking for this.

## Artificial Intelligence for the Climate Crisis üåç

* üåç There is now a [Climate Change AI Wiki](https://wiki.climatechange.ai/wiki/Welcome_to_the_Climate_Change_AI_Wiki?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). It has sections on climate + machine learning research into mitigation, adaptation, climate science, and tools for action. Some of my favorite pages so far are the ones on [electricity systems](https://wiki.climatechange.ai/wiki/Electricity_Systems?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [transportation](https://wiki.climatechange.ai/wiki/Transportation?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), [forestry and other land use](https://wiki.climatechange.ai/wiki/Forestry_and_Other_Land_Use?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), and [weather forecasting](https://wiki.climatechange.ai/wiki/Weather_forecasting?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). A good website to bookmark!

## Cool Things ‚ú®

![The Flemish Scrollers](https://s3.amazonaws.com/revue/items/images/010/146/177/mail/E5h7PmUWEAYkpXH.jpeg?1626534091)

_The Flemish Scrollers_

* üëÄ Belgian artist [Dries Depoorter](https://driesdepoorter.be/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) launched a project called [The Flemish Scrollers](https://driesdepoorter.be/theflemishscrollers/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) that watches daily live streams of the Flemish parliament and uses computer vision to detect when Belgian politicians are looking at their phone instead of paying attention. Whenever this happens, [@FlemishScroller](https://twitter.com/FlemishScroller?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) tattles on Twitter by tweeting a video clip and tagging the distracted politicians. Pretty funny!

**Thanks for reading!**
As usual, you can let me know what you thought of today‚Äôs issue using the buttons below or by replying to this email.
If you‚Äôre new here, check out the [Dynamically Typed archives](https://dynamicallytyped.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or subscribe below to get a new issues in your inbox every second Sunday.

**If you enjoyed this issue of Dynamically Typed, why not forward it to a friend?**
It‚Äôs by far the best thing you can do to help me grow this newsletter.
üèù