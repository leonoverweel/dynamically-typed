---
title: "#53: Runway ML&#x27;s Green Screen, new tools from EMNLP, and tracking illegal cattle farming with AI "
date: 2020-11-22
number: 53
aliases:
  - /issues/53-runway-ml-s-green-screen-new-tools-from-emnlp-and-tracking-illegal-cattle-farming-with-ai-292000
---

Hey everyone, welcome to Dynamically Typed #53!
It has one again been a very busy two weeks on my news feeds, so let‚Äôs dive straight in.

For productized AI, Runway ML launched the first (well, maybe) web-based automated video background removal tool; and Apple open-sourced a fork of TensorFlow 2 optimized for their new M1 Macs.
On the ML research side, I read a very cool new Distill paper about understanding vision in reinforcement learning agents; GitHub is embracing fast.ai‚Äôs nbdev; and two great new resources came out of the EMNLP 2020: a 274-slide tutorial on high-performance NLP, and the Language Interpretability Tool (LIT).
Next, for climate AI, a new paper accepted to the CCAI track at NeurIPS 2020 uses high-resolution satellite imagery to track illegal cattle farming; and Google‚Äôs AI blog has a feature about their Tree Canopy Lab.
Finally, in cool things: the NYT created an amazing interactive story about GAN-generated fake faces; and Google engineers used GANs to create fantastical creatures.

## Productized Artificial Intelligence üîå

* üü© [Runway ML](https://runwayml.com?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), the ‚Äúapp store‚Äù of easy-to-use machine learning models for creators (see [DT #18](https://dynamicallytyped.com/issues/18-runway-ml-s-app-store-for-ai-google-s-new-youtube-dataset-and-a-trippy-gan-journey-188184?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)), [added a new Green Screen feature](https://twitter.com/runwayml/status/1328692635037523968?s=12&utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), which it says is ‚Äú[the] first real-time web tool for cutting objects out of videos. Using machine learning, it makes rotoscoping (a.k.a. masking) a lot faster and a lot less painful.‚Äù It looks very cool, but take their claim of being first with a grain of salt: Kaleido, the folks behind DT-favorite [remove.bg](https://www.remove.bg?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), also launched an ML-powered automatic video background removal tool called [unscreen](https://www.unscreen.com?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) earlier this year ([#35](https://dynamicallytyped.com/issues/35-completely-automatic-video-background-removal-with-unscreen-and-circuits-for-understanding-neural-networks-230458?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)). However, for Runway ML, Green Screen represents yet another well-integrated feature for their already extensive AI creativity product, which is not something unscreen can match as a single-use tool. Along with Photoshop‚Äôs new AI features ([#51](https://dynamicallytyped.com/issues/51-photoshop-s-new-ai-features-descript-for-video-and-ar-copy-paste-with-clipdrop-284856?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)), this is yet another example of how quickly deep learning vision models are becoming easy to use for everyone.
* üçé [Apple has forked TensorFlow 2](https://blog.tensorflow.org/2020/11/accelerating-tensorflow-performance-on-mac.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) to optimize it for their new crazy-fast M1 Macs! This came as a pretty big surprise, and it makes the new M1 Macs even more attractive to ML developers: for the first time, this‚Äôll enable using the internal GPU to train TensorFlow models on Mac laptops, leadings to ~5x speedups (!) compared to the previous generation. I‚Äôll probably hold until for the next generation ‚Äî by which time Apple‚Äôs optimizations should also be upstreamed to the main TensorFlow branch instead of only being available on their own fork ‚Äî but it‚Äôs clear that even now these laptops are already huge game changers.

## Machine Learning Research üéõ

* üëæ Cool new Distill paper from Hilton et al. (2020): [Understanding RL Vision](https://distill.pub/2020/understanding-rl-vision/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). The authors train a reinforcement learning agent to play a procedurally-generated video game based on single frames as input, and then develop an interactive interface (embedded in the article!) to study what different parts of the network learn. Using [Circuits](https://distill.pub/2020/circuits/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) editing (see [DT #37](https://dynamicallytyped.com/issues/37-openai-s-neural-network-taxonomy-decoding-text-from-brain-implants-and-models-that-don-t-exist-236677?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)), they then make the agent blind to e.g. left-moving enemies in the game, and experimentally show that this indeed makes it fail more often by missing such enemies. ‚ÄúOur results depend on levels in CoinRun being procedurally-generated, leading us to formulate a diversity hypothesis for interpretability. _[Interpretable features tend to arise (at a given level of abstraction) if and only if the training distribution is diverse enough (at that level of abstraction).]_ If it is correct, then we can expect RL models to become more interpretable as the environments they are trained on become more diverse.‚Äù As always, [the full article](https://distill.pub/2020/understanding-rl-vision/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is a great Sunday long read.
* üìì Hamel Husain wrote in [a post on the GitHub blog](https://github.blog/2020-11-20-nbdev-a-literate-programming-environment-that-democratizes-software-engineering-best-practices/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) that the company is going to assist in developing [fast.ai](https://www.fast.ai?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)‚Äôs [nbdev](https://github.com/fastai/nbdev?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), a literate programming environment for Python. Donald Knuth describes literate programming as ‚Äúa move away from writing computer programs in the manner and order imposed by the computer, and instead enables programmers to develop programs in the order demanded by the logic and flow of their thoughts.‚Äù I linked to nbdev last year ([DT #28](https://dynamicallytyped.com/issues/28-ocr-for-latex-equations-night-sight-for-astrophotography-and-a-gpt-2-powered-text-adventure-212704?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) but haven‚Äôt seen it in the wild much since then. I‚Äôm also not yet convinced that this notebooks-centric approach scales to making large software projects easier to follow. (Maybe that‚Äôs just because I‚Äôm used to the current standard structures for Python projects?) But the fact that GitHub is embracing nbdev so enthusiastically makes me curious about how it‚Äôll develop in the coming years, and whether it‚Äôll start to pop up more outside of fast.ai‚Äôs courses/projects.
* ‚ö°Ô∏è Fantastic slides by Ilharco et al. (2020) for the EMNLP 2020 tutorial on [High Performance Natural Language Processing](http://gabrielilharco.com/publications/EMNLP_2020_Tutorial__High_Performance_NLP.pdf?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) (PDF), which got a lot of love on Twitter. [Alexander Rush](https://twitter.com/srush_nlp/status/1329500650447790084?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter): ‚ÄúEvery slide is current to the minute. Amazing set of diagrams.‚Äù [Jeff Dean](https://twitter.com/JeffDean/status/1330013793766711299?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter): ‚Äúhundreds of slides that will transform your understanding!‚Äù
* ‚ö°Ô∏è Also presented at EMNLP 2020, the [Language Interpretability Tool (LIT)](https://pair-code.github.io/lit/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) is an open-source platform for visualizing and understanding NLP models. It builds on top of Google‚Äôs previous [What-If Tool](https://whatif-tool.dev/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), and supports ‚Äúlocal explanations, including salience maps, attention, and rich visualizations of model predictions, as well as aggregate analysis including metrics, embedding spaces, and flexible slicing.‚Äù James Wexler and Ian Tenney introduce the tool in [a post on the Google AI Blog](https://ai.googleblog.com/2020/11/the-language-interpretability-tool-lit.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), which also includes a few demos.

_I‚Äôve also collected all 75+ ML research tools previously featured in Dynamically Typed_[ _on a Notion page_](https://www.notion.so/adab36fecaea4306880898f41dcb9cb3?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=cb3a74562c914234ac171931dad6c2e4) _for quick reference.
‚ö°Ô∏è_

## Artificial Intelligence for the Climate Crisis üåç

* üêÑ In collaboration with the NGO [Global Witness](https://globalwitness.org/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), which investigates human rights abuses surrounding conflicts over natural resources, [Laradji et al. (2020)](https://arxiv.org/abs/2011.07369?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) built a machine learning model to track illegal cattle ranching based on high-resolution (40cm) satellite imagery. ‚ÄúCattle farming is responsible for 8.8% of greenhouse gas emissions worldwide. ‚Ä¶ While some regulations are in place for preserving the Amazon against deforestation, these are being flouted in various ways, hence the need to scale and automate the monitoring of cattle ranching activities.‚Äù The paper has been accepted to the [Tackling Climate Change with ML Workshop](https://www.climatechange.ai/events/neurips2020.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) at NeurIPS 2020, and training code is available on GitHub at [IssamLaradji/cownter_strike](https://github.com/IssamLaradji/cownter_strike?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).
* üå≥ For Google‚Äôs The Keyword blog, Alicia Cormie wrote about how Los Angeles‚Äô first-ever City Forest Officer Rachel Malarich is using the company‚Äôs [Tree Canopy Lab](https://blog.google/products/earth/helping-cities-seed-new-trees-with-tree-canopy-lab/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) to [decide where to plant trees](https://blog.google/products/earth/rachel-malarich-planting-better-future/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). Tree Canopy Lab uses satellite imagery to automatically map a city‚Äôs tree cover density in different areas, which Cormie uses to find the communities most in need of more trees. Trees in cities are awesome: they improve air quality and reduce the effects of extreme climate change-induced heat. Plant more trees in cities! It‚Äôs great to see an ML-powered project being used to help with this.

## Cool Things ‚ú®

* üôç‚Äç‚ôÄÔ∏è If you‚Äôre going to click one link from today‚Äôs DT, make it this one. The New York Times‚Äô Kashmir Hill and Jeremy White wrote [an amazing new visual article about GAN-generated human faces](https://www.nytimes.com/interactive/2020/11/21/science/artificial-intelligence-fake-people-faces.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). It details how projects like [This Person Does Not Exist](https://thispersondoesnotexist.com?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) (see [DT #8](https://dynamicallytyped.com/issues/8-should-openai-open-source-their-impressive-new-language-model-161119?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) and Rosebud.AI ([#37](https://dynamicallytyped.com/issues/37-openai-s-neural-network-taxonomy-decoding-text-from-brain-implants-and-models-that-don-t-exist-236677?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) work, has embedded examples of latent space sliders that generate faces with different properties, and also includes some tips on spotting images with fake faces.
* üê© Related: Andeep Singh Toor and Fred Bertsch wrote a post for the Google AI blog about [Using GANs to Create Fantastical Creatures](http://ai.googleblog.com/2020/11/using-gans-to-create-fantastical.html?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter). I like the bunny-wolf, although it is more than slightly terrifying. The model, which ‚Äúautomatically creates a fully fleshed out rendering from a user-supplied creature outline,‚Äù is available as a downloadable demo called Chimera Painter.

**Thanks for reading!**
As usual, you can let me know what you thought of today‚Äôs issue using the buttons below or by replying to this email.
If you‚Äôre new here, check out the [Dynamically Typed archives](https://dynamicallytyped.com/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) or subscribe below to get a new issues in your inbox every second Sunday.

**If you enjoyed this issue of Dynamically Typed, why not forward it to a friend?**
It‚Äôs by far the best thing you can do to help me grow this newsletter.
üé®