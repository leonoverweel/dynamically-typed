---
category: cool-things
date: 2020-03-29
issue_number: 36
title: 'Neural radiance fields for view synthesis: NeRF'
---

![Novel views generated from pictures of a scene.](https://s3.amazonaws.com/revue/items/images/005/739/569/mail/a949c7f8405ad67fd07d8e807333782f.png?1585416173)

_Novel views generated from pictures of a scene._

**Representing Scenes as Neural Radiance Fields for View Synthesis,** or NeRF, is some very cool new research from researchers at UC Berkeley.
Using an input of 20-50 images of a scene taken at slightly different viewpoints, they are able to encode the scene into a fully-connected (non-convolutional) neural network that can then generate new viewpoints of the scene.
Itâ€™s hard to show this in static images like the ones I embedded above, so I highly recommend you check out the [excellent webpage for the research](http://www.matthewtancik.com/nerf?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and the [accompanying video](https://www.youtube.com/watch?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter&v=JuH79E8rdKc).