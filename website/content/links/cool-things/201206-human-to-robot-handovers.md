---
category: cool-things
date: 2020-12-06
emoji: "\U0001F9BE"
issue_number: 54
title: Reactive Human-to-Robot Handovers of Arbitrary Objects
---

This is a bit out of the scope of what I usually cover on DT, but I was obsessed with robot arms during high school and this new NVIDIA paper by [Yang et al.
(2020)](https://arxiv.org/abs/2011.08961?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) looks awesome.
Their project, [Reactive Human-to-Robot Handovers of Arbitrary Objects](https://sites.google.com/nvidia.com/handovers-of-arbitrary-objects?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), does exactly what it says on the tin: it uses computer vision to let the robot arm grasp arbitrary objects presented by the user.
This is a really difficult problem thatâ€™s key to building the kinds of robots we see in movies!
The researchers posted [a 3-minute demo video on YouTube](https://youtu.be/YYXqxRY76qY?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter), which is a fun watch.