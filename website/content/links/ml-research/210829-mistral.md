---
category: ml-research
date: 2021-08-29
emoji: "\u26A1\uFE0F"
issue_number: 73
title: Mistral by Stanford HAI CRFM
---

Stanford HAI’s new [Center for Research on Foundation Models](https://crfm.stanford.edu?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) (“foundation models” is their name for large self-supervised models like [GPT-3](https://dynamicallytyped.com/stories/2020/gpt-3/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter) and [CLIP](https://dynamicallytyped.com/stories/2021/openai-dall-e-clip/?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter)) has open-sourced Mistral, a “framework for transparent and accessible large-scale language model training.” It’s on GitHub at [stanford-crfm/mistral](https://github.com/stanford-crfm/mistral?utm_campaign=Dynamically%20Typed&utm_medium=email&utm_source=Revue%20newsletter).